# Stage 1 – item2vec CF 베이스라인 성능 보고서

## 1. 실험 개요
본 실험(Stage 1)의 목적은 Melon Playlist Dataset을 활용하여 **곡 기반 협업 필터링(Collaborative Filtering, CF) 베이스라인**을 구축하는 것입니다.
플레이리스트 내의 곡 시퀀스를 자연어의 "문장"으로, 각 곡(Song ID)을 "단어"로 간주하여 **item2vec (Word2Vec Skip-gram)** 모델을 학습시켰습니다. 이를 통해 사용자가 선택한 특정 곡과 함께 자주 청취되는 유사한 곡을 추천하는 기능을 구현하고, 그 성능을 정량적/정성적으로 평가했습니다.

## 2. 데이터 및 전처리
Melon Playlist Dataset의 `train.json` 데이터를 사용하여 학습을 진행했습니다.

- **총 플레이리스트 수:** 115,071개
- **고유 곡 ID 개수:** 615,142개 (전체 데이터 기준)

### 플레이리스트 길이 분포
학습 데이터의 플레이리스트 길이(수록 곡 수) 분포는 다음과 같습니다.

| 구분 | 곡 수 |
| :--- | :--- |
| 최소값 | 1곡 |
| 25% 백분위 | 19곡 |
| **중간값 (50%)** | **30곡** |
| 75% 백분위 | 54곡 |
| 최대값 | 200곡 |
| **평균** | **45.9곡** |

**구간별 분포:**
- 11~50곡 사이의 플레이리스트가 전체의 약 **69.1%**를 차지합니다.
- 100곡을 초과하는 긴 플레이리스트는 약 10.2%입니다.

### Window Size 선정 근거 (Window=10)
플레이리스트의 중간값 길이가 30곡, 평균이 약 46곡임을 고려하여 **Window Size를 10**으로 설정했습니다.
- 이는 중간값(30곡)의 약 1/3에 해당하는 크기로, 곡의 전후 맥락을 충분히 반영하면서도 너무 먼 거리의 곡까지 연관 짓지 않도록 하는 적절한 범위입니다.
- 짧은 플레이리스트(20곡 미만)에서는 거의 전체 맥락을 학습하고, 긴 플레이리스트에서는 국소적인 청취 흐름(Vibe)을 학습하도록 의도했습니다.

## 3. 모델 및 학습 설정
`gensim` 라이브러리의 `Word2Vec` 모델을 사용하여 SGNS(Skip-gram with Negative Sampling) 방식으로 학습했습니다.

### 주요 하이퍼파라미터
| 파라미터 | 설정값 | 설명 |
| :--- | :--- | :--- |
| **Algorithm** | SG (Skip-gram) | 중심 곡으로 주변 곡을 예측하며 학습 |
| **Embedding Dim** | 128 | 곡 벡터의 차원 수 |
| **Window Size** | 10 | 앞뒤 10곡을 컨텍스트로 사용 |
| **Min Count** | 3 | 3회 미만 등장 곡은 학습에서 제외 (노이즈 제거) |
| **Negative Sampling** | 10 | 오답(Negative) 샘플 개수 |
| **Epochs** | 5 | 전체 데이터 반복 학습 횟수 |

### 학습 데이터 필터링
- **최소 길이 제한:** 곡이 2개 미만인 플레이리스트는 시퀀스 생성에서 제외했습니다.

## 4. 평가 설정
모델의 성능을 측정하기 위해 **Recall@20** 지표를 사용했습니다.

### 평가 프로토콜
1. **데이터셋:** 전체 플레이리스트 중 곡이 10개 이상인 플레이리스트를 대상으로 함.
2. **샘플링:** 전체 평가 시간을 고려하여 무작위로 **1,000개**의 플레이리스트를 샘플링하여 평가.
3. **방법:**
    - 각 플레이리스트의 **첫 번째 곡**을 시드(Seed) 곡으로 선정.
    - 나머지 곡들을 정답(Ground Truth) 집합으로 정의.
    - 모델을 통해 시드 곡과 유사도가 높은 **Top-20** 곡을 추천.
    - 추천된 20곡 중 정답 집합에 포함된 곡의 비율을 계산.

> **참고:** 이 평가는 실제 사용자의 반응을 보는 것이 아니라, "같은 플레이리스트에 있던 곡을 얼마나 잘 복원하는가"를 보는 기본적인 일관성 테스트(Smoke Test) 수준입니다.

## 5. 정량적 성능 결과
1,000개의 샘플 플레이리스트에 대한 평가 결과는 다음과 같습니다.

| 지표 | 결과값 | 비고 |
| :--- | :--- | :--- |
| **평균 Recall@20** | **0.0249 (2.49%)** | |
| **Cold Start 비율** | **8.5%** | 시드 곡이 모델에 없어 추천 불가한 케이스 |

### 결과 해석
- **낮은 수치:** 평균 2.49%의 Recall은 일반적인 상용 추천 시스템(10~20% 이상)에 비해 낮은 수치입니다. 이는 단일 시드 곡만으로는 전체 플레이리스트의 맥락을 파악하기 어렵다는 CF의 한계를 보여줍니다.
- **Cold Start 문제:** 평가 대상 중 약 **8.5%**의 시드 곡이 모델 학습 과정(Min Count=3)에서 제외되어 추천 결과를 생성하지 못했습니다. 이는 희귀 곡(Long-tail)에 대한 대응책이 필요함을 시사합니다.
- **분포 편중:** 대부분의 케이스에서 Recall이 0~5% 구간에 머물렀습니다.

## 6. 추천 예시 및 정성적 해석
실제 모델이 생성한 추천 결과 예시입니다. (메타데이터 미연동으로 ID만 표시)

**시드 곡 ID:** `525514`

| 순위 | Song ID | 유사도 (Cosine Similarity) |
| :---: | :---: | :---: |
| 1 | 695342 | 0.9843 |
| 2 | 402336 | 0.9814 |
| 3 | 569182 | 0.9793 |
| 4 | 442125 | 0.9788 |
| 5 | 423887 | 0.9785 |

### 해석
- 유사도 점수가 0.98 이상으로 매우 높게 형성되어 있습니다. 이는 item2vec 모델이 특정 곡들이 매우 밀접하게 함께 등장하는 패턴을 잘 학습했음을 의미합니다.
- 다만, 현재 단계에서는 곡 제목이나 아티스트 정보를 확인할 수 없어 직관적인 품질 평가는 어렵습니다. Stage 1.5에서 메타데이터(`song_meta.json`)를 결합하면 장르나 아티스트의 일관성을 확인할 수 있을 것입니다.

## 7. 한계점 및 개선 방향

### 한계점
1.  **메타데이터 부재:** 순수하게 플레이리스트 내 동시 등장 여부만 학습하므로, 장르나 아티스트 정보가 반영되지 않았습니다.
2.  **Cold Start:** 3회 미만 등장한 희귀 곡(Long-tail)에 대해서는 추천이 불가능합니다 (약 8.5% 발생).
3.  **단순한 평가:** 단일 곡으로 전체 플레이리스트를 예측하는 것은 매우 어려운 과제이며, 실제 사용자의 만족도와는 괴리가 있을 수 있습니다.

### 개선 방향 (Next Steps)
1.  **Stage 1.5 (메타데이터 결합):** `song_meta.json`을 연동하여 추천 결과에 곡명/아티스트를 표시하고, 장르/아티스트 기반의 **Re-ranking** 규칙을 적용하여 품질을 보정합니다.
2.  **Stage 2 (하이브리드 모델):** Mel-spectrogram 기반의 오디오 임베딩을 결합하여, 학습되지 않은 신곡(Cold Start)이나 청취 패턴이 부족한 곡에 대해서도 "오디오 분위기(Vibe)" 기반의 추천이 가능하도록 확장합니다.
3.  **평가 고도화:** Recall 외에도 다양성(Diversity)이나 참신성(Serendipity)을 고려한 정성적 평가를 병행합니다.

## 8. 결론
Stage 1을 통해 **곡 기반 협업 필터링의 파이프라인(데이터 로드 → 전처리 → 모델 학습 → 추천 → 평가)**을 성공적으로 구축했습니다.
현재의 정량적 성능(Recall 2.5%)은 다소 낮지만, 이는 아무런 메타데이터나 오디오 정보 없이 순수 청취 패턴만으로 학습한 베이스라인이라는 점에서 의미가 있습니다.
이 베이스라인 모델은 향후 메타데이터 필터링과 오디오 기반 추천을 결합하여 성능을 점진적으로 개선해 나갈 **탄탄한 출발점**이 될 것입니다.
