{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# VibeCurator - Stage 1: Item2Vec Baseline\n",
                "\n",
                "Ïù¥ ÎÖ∏Ìä∏Î∂ÅÏùÄ Melon Playlist DatasetÏùò train.jsonÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ **item2vec(Word2Vec-SGNS)** Î∞©ÏãùÏúºÎ°ú Í≥° ÏûÑÎ≤†Îî©ÏùÑ ÌïôÏäµÌï©ÎãàÎã§.\n",
                "\n",
                "Í∞Å ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏Ïùò Í≥° ÏãúÌÄÄÏä§Î•º \"Î¨∏Ïû•\", Í≥° IDÎ•º \"Îã®Ïñ¥\"Î°ú Ï∑®Í∏âÌïòÏó¨ CF(Collaborative Filtering) Í∏∞Î∞ò Í≥° Ï∂îÏ≤úÏùÑ Íµ¨ÌòÑÌï©ÎãàÎã§."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Step 0 ÏôÑÎ£å: ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∞è ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï ÏôÑÎ£å\n",
                        "   - ÏûÑÎ≤†Îî© Ï∞®Ïõê: 128\n",
                        "   - ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞: 10\n",
                        "   - ÌïôÏäµ ÏóêÌè≠: 5\n"
                    ]
                }
            ],
            "source": [
                "# Step 0: Í∏∞Î≥∏ ÏÑ§Ï†ï\n",
                "# ÌïÑÏàò ÎùºÏù¥Î∏åÎü¨Î¶¨ import Î∞è ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Ï†ïÏùò\n",
                "\n",
                "import json\n",
                "import os\n",
                "import logging\n",
                "from multiprocessing import cpu_count\n",
                "import numpy as np\n",
                "from gensim.models import Word2Vec\n",
                "import pandas as pd  # Í∞ÑÎã® ÌôïÏù∏Ïö©\n",
                "\n",
                "# Î°úÍπÖ Í∏∞Î≥∏ ÏÑ§Ï†ï\n",
                "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "# ========================================\n",
                "# Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú ÏÑ§Ï†ï (recommend_model Ìè¥Îçî Í∏∞Ï§Ä)\n",
                "# ========================================\n",
                "DATA_ROOT = \"../melon-dataset-excepttar\"  # recommend_model Ìè¥Îçî Í∏∞Ï§Ä\n",
                "TRAIN_JSON_PATH = os.path.join(DATA_ROOT, \"train.json\")\n",
                "\n",
                "# Î™®Îç∏ Ï†ÄÏû• Í≤ΩÎ°ú\n",
                "MODEL_DIR = \"../models\"  # recommend_model Ìè¥Îçî Í∏∞Ï§Ä\n",
                "os.makedirs(MODEL_DIR, exist_ok=True)\n",
                "\n",
                "# ========================================\n",
                "# item2vec ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
                "# ========================================\n",
                "HYPERPARAMS = {\n",
                "    \"EMBEDDING_DIM\": 128,      # ÏûÑÎ≤†Îî© Ï∞®Ïõê\n",
                "    \"WINDOW_SIZE\": 10,         # Ïª®ÌÖçÏä§Ìä∏ ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞ (ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ ÎÇ¥ Í≥° Í∞ÑÍ≤©)\n",
                "    \"MIN_COUNT\": 2,            # ÏµúÏÜå Ï∂úÌòÑ ÌöüÏàò (2Ìöå ÎØ∏Îßå Í≥°ÏùÄ Ï†úÏô∏)\n",
                "    \"NEGATIVE\": 10,            # Negative sampling Í∞úÏàò\n",
                "    \"EPOCHS\": 5,               # ÌïôÏäµ ÏóêÌè≠ Ïàò\n",
                "    \"SG\": 1,                   # Skip-gram (1) or CBOW (0)\n",
                "    \"WORKERS\": cpu_count()     # Î©ÄÌã∞ÌîÑÎ°úÏÑ∏Ïã± ÏõåÏª§ Ïàò\n",
                "}\n",
                "\n",
                "logger.info(\"‚úÖ Step 0 ÏôÑÎ£å: ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∞è ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï ÏôÑÎ£å\")\n",
                "logger.info(f\"   - ÏûÑÎ≤†Îî© Ï∞®Ïõê: {HYPERPARAMS['EMBEDDING_DIM']}\")\n",
                "logger.info(f\"   - ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞: {HYPERPARAMS['WINDOW_SIZE']}\")\n",
                "logger.info(f\"   - ÌïôÏäµ ÏóêÌè≠: {HYPERPARAMS['EPOCHS']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "üìÇ Step 1 ÏãúÏûë: train.json Î°úÎìú Ï§ë...\n",
                        "‚úÖ train.json Î°úÎìú ÏôÑÎ£å\n",
                        "\n",
                        "üìä Í∏∞Î≥∏ ÌÜµÍ≥Ñ:\n",
                        "   - Ï¥ù ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Ïàò: 115,071\n",
                        "\n",
                        "üìù Ï≤´ Î≤àÏß∏ ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Íµ¨Ï°∞:\n",
                        "   - Keys: ['tags', 'id', 'plylst_title', 'songs', 'like_cnt', 'updt_date']\n",
                        "   - Í≥° Ïàò: 19\n",
                        "   - ÏòàÏãú song_id: [525514, 129701, 383374, 562083, 297861]\n",
                        "\n",
                        "üéµ Í≥° ÌÜµÍ≥Ñ:\n",
                        "   - Í≥†Ïú† Í≥° ID Í∞úÏàò: 615,142\n",
                        "\n",
                        "üìè ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Í∏∏Ïù¥ Î∂ÑÌè¨ (Window Size Ï∞∏Í≥†Ïö©):\n",
                        "   - ÏµúÏÜåÍ∞í: 1Í≥°\n",
                        "   - 25% Î∞±Î∂ÑÏúÑ: 19Í≥°\n",
                        "   - 50% Î∞±Î∂ÑÏúÑ (Ï§ëÍ∞ÑÍ∞í): 30Í≥°\n",
                        "   - 75% Î∞±Î∂ÑÏúÑ: 54Í≥°\n",
                        "   - 90% Î∞±Î∂ÑÏúÑ: 100Í≥°\n",
                        "   - 95% Î∞±Î∂ÑÏúÑ: 156Í≥°\n",
                        "   - ÏµúÎåÄÍ∞í: 200Í≥°\n",
                        "   - ÌèâÍ∑†: 45.9Í≥°\n",
                        "   - ÌëúÏ§ÄÌé∏Ï∞®: 44.0Í≥°\n",
                        "\n",
                        "üìä ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Í∏∏Ïù¥ Íµ¨Í∞ÑÎ≥Ñ Î∂ÑÌè¨:\n",
                        "   - 1-10Í≥°       :  3,164Í∞ú (  2.7%)\n",
                        "   - 11-20Í≥°      : 26,753Í∞ú ( 23.2%)\n",
                        "   - 21-30Í≥°      : 27,500Í∞ú ( 23.9%)\n",
                        "   - 31-50Í≥°      : 25,372Í∞ú ( 22.0%)\n",
                        "   - 51-100Í≥°     : 20,523Í∞ú ( 17.8%)\n",
                        "   - 100Í≥° Ï¥àÍ≥º     : 11,759Í∞ú ( 10.2%)\n",
                        "\n",
                        "üí° Window Size Ï∂îÏ≤ú:\n",
                        "   - Ï§ëÍ∞ÑÍ∞íÏùò Ï†àÎ∞ò Í∏∞Ï§Ä: 15\n",
                        "   - Î≥¥ÏàòÏ†Å ÏÑ§Ï†ï (ÏßßÏùÄ ÌîåÎ¶¨ Í≥†Î†§): 5-10\n",
                        "   - Ï†ÅÍ∑πÏ†Å ÏÑ§Ï†ï (Í∏¥ ÌîåÎ¶¨ ÌôúÏö©): 10-20\n",
                        "   - ÌòÑÏû¨ ÏÑ§Ï†ïÍ∞í: 10\n",
                        "\n",
                        "‚úÖ Step 1 ÏôÑÎ£å: Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è Í∏∞Î≥∏ ÌÜµÍ≥Ñ ÌôïÏù∏ ÏôÑÎ£å\n"
                    ]
                }
            ],
            "source": [
                "# Step 1: Îç∞Ïù¥ÌÑ∞ Î°úÎìú & Í∏∞Î≥∏ ÌÜµÍ≥Ñ\n",
                "# train.jsonÏùÑ Î°úÎìúÌïòÍ≥† ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Î∞è Í≥° Í∏∞Î≥∏ Ï†ïÎ≥¥Î•º ÌôïÏù∏Ìï©ÎãàÎã§\n",
                "\n",
                "logger.info(\"üìÇ Step 1 ÏãúÏûë: train.json Î°úÎìú Ï§ë...\")\n",
                "\n",
                "# train.json Î°úÎìú\n",
                "# TODO: ÎåÄÏö©Îüâ Îç∞Ïù¥ÌÑ∞Ïùò Í≤ΩÏö∞ Î©îÎ™®Î¶¨ Ïù¥ÏäàÍ∞Ä ÏûàÏùÑ Ïàò ÏûàÏúºÎãà, generator Î∞©ÏãùÏúºÎ°ú Î≥ÄÍ≤Ω Í≥†Î†§\n",
                "with open(TRAIN_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
                "    train_data = json.load(f)\n",
                "\n",
                "logger.info(f\"‚úÖ train.json Î°úÎìú ÏôÑÎ£å\")\n",
                "\n",
                "# ========================================\n",
                "# Í∏∞Î≥∏ ÌÜµÍ≥Ñ ÌôïÏù∏\n",
                "# ========================================\n",
                "num_playlists = len(train_data)\n",
                "logger.info(f\"\\nüìä Í∏∞Î≥∏ ÌÜµÍ≥Ñ:\")\n",
                "logger.info(f\"   - Ï¥ù ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Ïàò: {num_playlists:,}\")\n",
                "\n",
                "# Ï≤´ Î≤àÏß∏ ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Íµ¨Ï°∞ ÌôïÏù∏\n",
                "sample_playlist = train_data[0]\n",
                "logger.info(f\"\\nüìù Ï≤´ Î≤àÏß∏ ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Íµ¨Ï°∞:\")\n",
                "logger.info(f\"   - Keys: {list(sample_playlist.keys())}\")\n",
                "logger.info(f\"   - Í≥° Ïàò: {len(sample_playlist.get('songs', []))}\")\n",
                "logger.info(f\"   - ÏòàÏãú song_id: {sample_playlist.get('songs', [])[:5]}\")\n",
                "\n",
                "# Í≥†Ïú† Í≥° ID Í∞úÏàò Î∞è ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Í∏∏Ïù¥ Í≥ÑÏÇ∞\n",
                "all_song_ids = set()\n",
                "playlist_lengths = []\n",
                "\n",
                "for playlist in train_data:\n",
                "    songs = playlist.get('songs', [])\n",
                "    all_song_ids.update(songs)\n",
                "    playlist_lengths.append(len(songs))\n",
                "\n",
                "logger.info(f\"\\nüéµ Í≥° ÌÜµÍ≥Ñ:\")\n",
                "logger.info(f\"   - Í≥†Ïú† Í≥° ID Í∞úÏàò: {len(all_song_ids):,}\")\n",
                "\n",
                "# ========================================\n",
                "# ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Í∏∏Ïù¥ ÏÉÅÏÑ∏ ÌÜµÍ≥Ñ (Window Size Ï°∞Ï†ïÏö©)\n",
                "# ========================================\n",
                "logger.info(f\"\\nüìè ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Í∏∏Ïù¥ Î∂ÑÌè¨ (Window Size Ï∞∏Í≥†Ïö©):\")\n",
                "logger.info(f\"   - ÏµúÏÜåÍ∞í: {min(playlist_lengths)}Í≥°\")\n",
                "logger.info(f\"   - 25% Î∞±Î∂ÑÏúÑ: {np.percentile(playlist_lengths, 25):.0f}Í≥°\")\n",
                "logger.info(f\"   - 50% Î∞±Î∂ÑÏúÑ (Ï§ëÍ∞ÑÍ∞í): {np.percentile(playlist_lengths, 50):.0f}Í≥°\")\n",
                "logger.info(f\"   - 75% Î∞±Î∂ÑÏúÑ: {np.percentile(playlist_lengths, 75):.0f}Í≥°\")\n",
                "logger.info(f\"   - 90% Î∞±Î∂ÑÏúÑ: {np.percentile(playlist_lengths, 90):.0f}Í≥°\")\n",
                "logger.info(f\"   - 95% Î∞±Î∂ÑÏúÑ: {np.percentile(playlist_lengths, 95):.0f}Í≥°\")\n",
                "logger.info(f\"   - ÏµúÎåÄÍ∞í: {max(playlist_lengths)}Í≥°\")\n",
                "logger.info(f\"   - ÌèâÍ∑†: {np.mean(playlist_lengths):.1f}Í≥°\")\n",
                "logger.info(f\"   - ÌëúÏ§ÄÌé∏Ï∞®: {np.std(playlist_lengths):.1f}Í≥°\")\n",
                "\n",
                "# Í∏∏Ïù¥Î≥Ñ ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Í∞úÏàò Î∂ÑÌè¨\n",
                "logger.info(f\"\\nüìä ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Í∏∏Ïù¥ Íµ¨Í∞ÑÎ≥Ñ Î∂ÑÌè¨:\")\n",
                "bins = [0, 10, 20, 30, 50, 100, float('inf')]\n",
                "labels = ['1-10Í≥°', '11-20Í≥°', '21-30Í≥°', '31-50Í≥°', '51-100Í≥°', '100Í≥° Ï¥àÍ≥º']\n",
                "hist, _ = np.histogram(playlist_lengths, bins=bins)\n",
                "\n",
                "for label, count in zip(labels, hist):\n",
                "    percentage = (count / len(playlist_lengths)) * 100\n",
                "    logger.info(f\"   - {label:12s}: {count:6,}Í∞ú ({percentage:5.1f}%)\")\n",
                "\n",
                "# Window Size Ï∂îÏ≤ú\n",
                "median_len = np.median(playlist_lengths)\n",
                "recommended_window = int(median_len / 2)\n",
                "logger.info(f\"\\nüí° Window Size Ï∂îÏ≤ú:\")\n",
                "logger.info(f\"   - Ï§ëÍ∞ÑÍ∞íÏùò Ï†àÎ∞ò Í∏∞Ï§Ä: {recommended_window}\")\n",
                "logger.info(f\"   - Î≥¥ÏàòÏ†Å ÏÑ§Ï†ï (ÏßßÏùÄ ÌîåÎ¶¨ Í≥†Î†§): 5-10\")\n",
                "logger.info(f\"   - Ï†ÅÍ∑πÏ†Å ÏÑ§Ï†ï (Í∏¥ ÌîåÎ¶¨ ÌôúÏö©): 10-20\")\n",
                "logger.info(f\"   - ÌòÑÏû¨ ÏÑ§Ï†ïÍ∞í: {HYPERPARAMS['WINDOW_SIZE']}\")\n",
                "\n",
                "logger.info(\"\\n‚úÖ Step 1 ÏôÑÎ£å: Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è Í∏∞Î≥∏ ÌÜµÍ≥Ñ ÌôïÏù∏ ÏôÑÎ£å\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-11-26 21:15:17,048 - INFO - \n",
                        "üß™ PlaylistSentenceIterator ÌÖåÏä§Ìä∏...\n",
                        "2025-11-26 21:15:17,049 - INFO - üîÑ PlaylistSentenceIterator Ï¥àÍ∏∞Ìôî: ÏµúÏÜå Í≥° Ïàò = 2\n",
                        "2025-11-26 21:15:17,087 - INFO -    - Î¨∏Ïû• 1: 19Í∞ú ÌÜ†ÌÅ∞, ÏòàÏãú: ['525514', '129701', '383374', '562083', '297861']\n",
                        "2025-11-26 21:15:17,088 - INFO -    - Î¨∏Ïû• 2: 42Í∞ú ÌÜ†ÌÅ∞, ÏòàÏãú: ['432406', '675945', '497066', '120377', '389529']\n",
                        "2025-11-26 21:15:17,088 - INFO -    - Î¨∏Ïû• 3: 28Í∞ú ÌÜ†ÌÅ∞, ÏòàÏãú: ['83116', '276692', '166267', '186301', '354465']\n",
                        "2025-11-26 21:15:17,089 - INFO - \n",
                        "‚úÖ Step 2 ÏôÑÎ£å: PlaylistSentenceIterator Ï†ïÏùò Î∞è ÌÖåÏä§Ìä∏ ÏôÑÎ£å\n"
                    ]
                }
            ],
            "source": [
                "# Step 2: ÏãúÌÄÄÏä§ ÏÉùÏÑ±Ïö© ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
                "# PlaylistSentenceIteratorÎäî ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏Î•º \"Î¨∏Ïû•(Í≥° ID ÏãúÌÄÄÏä§)\"ÏúºÎ°ú Î≥ÄÌôòÌïòÎäî iteratorÏûÖÎãàÎã§\n",
                "\n",
                "class PlaylistSentenceIterator:\n",
                "    \"\"\"\n",
                "    Melon ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏Î•º gensim Word2VecÏù¥ Ïù¥Ìï¥Ìï† Ïàò ÏûàÎäî Î¨∏Ïû•(ÌÜ†ÌÅ∞ Î¶¨Ïä§Ìä∏)ÏúºÎ°ú Î≥ÄÌôòÌïòÎäî iterator\n",
                "    \n",
                "    Args:\n",
                "        playlists: train.jsonÏóêÏÑú Î°úÎìúÌïú ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Î¶¨Ïä§Ìä∏\n",
                "        min_len: ÏµúÏÜå Í≥° Í∞úÏàò (Ïù¥Î≥¥Îã§ ÏßßÏùÄ ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏Îäî Ï†úÏô∏)\n",
                "    \n",
                "    Yields:\n",
                "        List[str]: Í≥° IDÎ•º Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôòÌïú ÌÜ†ÌÅ∞ Î¶¨Ïä§Ìä∏\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, playlists, min_len=2):\n",
                "        self.playlists = playlists\n",
                "        self.min_len = min_len\n",
                "        logger.info(f\"üîÑ PlaylistSentenceIterator Ï¥àÍ∏∞Ìôî: ÏµúÏÜå Í≥° Ïàò = {min_len}\")\n",
                "    \n",
                "    def __iter__(self):\n",
                "        for playlist in self.playlists:\n",
                "            songs = playlist.get('songs', [])\n",
                "            \n",
                "            # Í≥° ÏàòÍ∞Ä ÏµúÏÜå Í∏∏Ïù¥Î≥¥Îã§ Ï†ÅÏúºÎ©¥ Í±¥ÎÑàÎõ∞Í∏∞\n",
                "            if len(songs) < self.min_len:\n",
                "                continue\n",
                "            \n",
                "            # Í≥° IDÎ•º Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôòÌïòÏó¨ yield\n",
                "            # NOTE: gensim Word2VecÏùÄ Î¨∏ÏûêÏó¥ ÌÜ†ÌÅ∞ÏùÑ Î∞õÏäµÎãàÎã§\n",
                "            yield [str(song_id) for song_id in songs]\n",
                "\n",
                "# ========================================\n",
                "# Í∞ÑÎã®Ìïú ÌÖåÏä§Ìä∏\n",
                "# ========================================\n",
                "logger.info(\"\\nüß™ PlaylistSentenceIterator ÌÖåÏä§Ìä∏...\")\n",
                "\n",
                "iterator = PlaylistSentenceIterator(train_data, min_len=2)\n",
                "iterator_test = iter(iterator)\n",
                "#iter(obj) ‚Üí obj.__iter__()Î•º Ìò∏Ï∂ú : iter ÎùºÎäî ÎÇ¥Ïû•Ìï®Ïàò\n",
                "\n",
                "# Ï≤òÏùå 3Í∞ú Î¨∏Ïû• ÏÉòÌîå Ï∂úÎ†•\n",
                "# next()Î°ú iterator_testÎ•º Ìò∏Ï∂ú , iterator_test = iter(iterator) ÎãàÍπê iter Ìï®ÏàòÎ•º Ìò∏Ï∂ú\n",
                "# iter Ìï®ÏàòÏóêÏÑú song_idÎ•º word2vecÎ™®Îç∏Ïù¥ Î∞õÏùÑ ÏàòÏûàÍ≤å strÎ°ú ÌòïÎ≥ÄÌôò\n",
                "# yield Î¨∏ÏúºÎ°ú Î¶¨ÌÑ¥ ÌïòÎØÄÎ°ú ÌïúÎ≤àÏóê ÌïòÎÇòÏî© Î∞òÌôò Í∞ÄÎä•\n",
                "# rage(3) Ï¶â ÏÑ∏Î≤àÎèôÏïà next()Î°ú Î∞òÎ≥µÌï¥ÏÑú ÌÅ¥ÎûòÏä§Í∞Ä Ïûò ÏûëÎèôÌïòÎÇò ÌôïÏù∏\n",
                "for i in range(3):\n",
                "    sentence = next(iterator_test)\n",
                "    logger.info(f\"   - Î¨∏Ïû• {i+1}: {len(sentence)}Í∞ú ÌÜ†ÌÅ∞, ÏòàÏãú: {sentence[:5]}\")\n",
                "\n",
                "logger.info(\"\\n‚úÖ Step 2 ÏôÑÎ£å: PlaylistSentenceIterator Ï†ïÏùò Î∞è ÌÖåÏä§Ìä∏ ÏôÑÎ£å\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-11-26 21:15:20,386 - INFO - ‚úÖ Step 3 ÏôÑÎ£å: train_item2vec Ìï®Ïàò Ï†ïÏùò ÏôÑÎ£å\n"
                    ]
                }
            ],
            "source": [
                "# Step 3: item2vec ÌïôÏäµ Ìï®Ïàò Ï†ïÏùò\n",
                "# Word2Vec-SGNS Î∞©ÏãùÏúºÎ°ú Í≥° ÏûÑÎ≤†Îî©ÏùÑ ÌïôÏäµÌïòÎäî Ìï®ÏàòÎ•º Ï†ïÏùòÌï©ÎãàÎã§\n",
                "\n",
                "def train_item2vec(sentences, hyperparams):\n",
                "    \"\"\"\n",
                "    gensim Word2VecÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ item2vec Î™®Îç∏ÏùÑ ÌïôÏäµÌï©ÎãàÎã§.\n",
                "    \n",
                "    Args:\n",
                "        sentences: PlaylistSentenceIterator ÎòêÎäî ÌÜ†ÌÅ∞ Î¶¨Ïä§Ìä∏Ïùò Î¶¨Ïä§Ìä∏\n",
                "        hyperparams: ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÎîïÏÖîÎÑàÎ¶¨\n",
                "    \n",
                "    Returns:\n",
                "        gensim.models.Word2Vec: ÌïôÏäµÎêú Word2Vec Î™®Îç∏\n",
                "    \"\"\"\n",
                "    logger.info(\"\\nüöÄ item2vec ÌïôÏäµ ÏãúÏûë...\")\n",
                "    logger.info(f\"   - ÏûÑÎ≤†Îî© Ï∞®Ïõê: {hyperparams['EMBEDDING_DIM']}\")\n",
                "    logger.info(f\"   - ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞: {hyperparams['WINDOW_SIZE']}\")\n",
                "    logger.info(f\"   - ÏµúÏÜå Ï∂úÌòÑ ÌöüÏàò: {hyperparams['MIN_COUNT']}\")\n",
                "    logger.info(f\"   - Negative sampling: {hyperparams['NEGATIVE']}\")\n",
                "    logger.info(f\"   - ÏóêÌè≠: {hyperparams['EPOCHS']}\")\n",
                "    \n",
                "    # NOTE: iteratorÎ•º Îëê Î≤à ÏÇ¨Ïö©ÌïòÍ∏∞ ÏúÑÌï¥ Î¶¨Ïä§Ìä∏Î°ú Ï∫êÏã±\n",
                "    # TODO: Î©îÎ™®Î¶¨Í∞Ä Î∂ÄÏ°±Ìïú Í≤ΩÏö∞, corpus_file ÏòµÏÖòÏùÑ ÏÇ¨Ïö©Ìïú ÎîîÏä§ÌÅ¨ Í∏∞Î∞ò ÌïôÏäµ Í≥†Î†§\n",
                "    logger.info(\"   - Î¨∏Ïû• Î¶¨Ïä§Ìä∏ Ï∫êÏã± Ï§ë... (Î©îÎ™®Î¶¨ ÏÇ¨Ïö© Ï£ºÏùò)\")\n",
                "    sentences_list = list(sentences)\n",
                "    logger.info(f\"   - Ï¥ù {len(sentences_list):,}Í∞ú ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Ï§ÄÎπÑ ÏôÑÎ£å\")\n",
                "    \n",
                "    # Word2Vec Î™®Îç∏ ÏÉùÏÑ±\n",
                "    model = Word2Vec(\n",
                "        vector_size=hyperparams['EMBEDDING_DIM'],\n",
                "        window=hyperparams['WINDOW_SIZE'],\n",
                "        min_count=hyperparams['MIN_COUNT'],\n",
                "        sg=hyperparams['SG'],  # Skip-gram\n",
                "        negative=hyperparams['NEGATIVE'],\n",
                "        workers=hyperparams['WORKERS'],\n",
                "        epochs=hyperparams['EPOCHS'],\n",
                "        seed=42  # Ïû¨ÌòÑÏÑ±ÏùÑ ÏúÑÌïú ÏãúÎìú\n",
                "    )\n",
                "    \n",
                "    # Vocabulary Íµ¨Ï∂ï\n",
                "    logger.info(\"\\nüìö Vocabulary Íµ¨Ï∂ï Ï§ë...\")\n",
                "    model.build_vocab(sentences_list, progress_per=10000)\n",
                "    logger.info(f\"   - Vocabulary ÌÅ¨Í∏∞: {len(model.wv):,}Í∞ú Í≥°\")\n",
                "    \n",
                "    # Î™®Îç∏ ÌïôÏäµ\n",
                "    logger.info(\"\\nüî• Î™®Îç∏ ÌïôÏäµ Ï§ë...\")\n",
                "    model.train(\n",
                "        sentences_list,\n",
                "        total_examples=model.corpus_count,\n",
                "        epochs=model.epochs,\n",
                "        report_delay=1.0\n",
                "    )\n",
                "    \n",
                "    logger.info(\"\\n‚úÖ item2vec ÌïôÏäµ ÏôÑÎ£å!\")\n",
                "    logger.info(f\"   - ÏµúÏ¢Ö Vocabulary ÌÅ¨Í∏∞: {len(model.wv):,}Í∞ú Í≥°\")\n",
                "    \n",
                "    return model\n",
                "\n",
                "logger.info(\"‚úÖ Step 3 ÏôÑÎ£å: train_item2vec Ìï®Ïàò Ï†ïÏùò ÏôÑÎ£å\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-11-26 21:15:24,960 - INFO - \n",
                        "============================================================\n",
                        "2025-11-26 21:15:24,961 - INFO - Step 4: item2vec Î™®Îç∏ ÌïôÏäµ Ïã§Ìñâ\n",
                        "2025-11-26 21:15:24,962 - INFO - ============================================================\n",
                        "2025-11-26 21:15:24,963 - INFO - üîÑ PlaylistSentenceIterator Ï¥àÍ∏∞Ìôî: ÏµúÏÜå Í≥° Ïàò = 2\n",
                        "2025-11-26 21:15:24,964 - INFO - \n",
                        "üöÄ item2vec ÌïôÏäµ ÏãúÏûë...\n",
                        "2025-11-26 21:15:24,964 - INFO -    - ÏûÑÎ≤†Îî© Ï∞®Ïõê: 128\n",
                        "2025-11-26 21:15:24,965 - INFO -    - ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞: 10\n",
                        "2025-11-26 21:15:24,965 - INFO -    - ÏµúÏÜå Ï∂úÌòÑ ÌöüÏàò: 2\n",
                        "2025-11-26 21:15:24,966 - INFO -    - Negative sampling: 10\n",
                        "2025-11-26 21:15:24,966 - INFO -    - ÏóêÌè≠: 5\n",
                        "2025-11-26 21:15:24,966 - INFO -    - Î¨∏Ïû• Î¶¨Ïä§Ìä∏ Ï∫êÏã± Ï§ë... (Î©îÎ™®Î¶¨ ÏÇ¨Ïö© Ï£ºÏùò)\n",
                        "2025-11-26 21:15:34,555 - INFO -    - Ï¥ù 115,040Í∞ú ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Ï§ÄÎπÑ ÏôÑÎ£å\n",
                        "2025-11-26 21:15:34,586 - INFO - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=128, alpha=0.025>', 'datetime': '2025-11-26T21:15:34.584785', 'gensim': '4.4.0', 'python': '3.13.7 | packaged by Anaconda, Inc. | (main, Sep  9 2025, 19:54:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n",
                        "2025-11-26 21:15:34,588 - INFO - \n",
                        "üìö Vocabulary Íµ¨Ï∂ï Ï§ë...\n",
                        "2025-11-26 21:15:34,590 - INFO - collecting all words and their counts\n",
                        "2025-11-26 21:15:34,592 - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
                        "2025-11-26 21:15:34,710 - INFO - PROGRESS: at sentence #10000, processed 457511 words, keeping 157469 word types\n",
                        "2025-11-26 21:15:34,859 - INFO - PROGRESS: at sentence #20000, processed 916681 words, keeping 239249 word types\n",
                        "2025-11-26 21:15:35,014 - INFO - PROGRESS: at sentence #30000, processed 1376230 words, keeping 302964 word types\n",
                        "2025-11-26 21:15:35,193 - INFO - PROGRESS: at sentence #40000, processed 1840602 words, keeping 357256 word types\n",
                        "2025-11-26 21:15:35,364 - INFO - PROGRESS: at sentence #50000, processed 2301703 words, keeping 401306 word types\n",
                        "2025-11-26 21:15:35,534 - INFO - PROGRESS: at sentence #60000, processed 2767883 words, keeping 441923 word types\n",
                        "2025-11-26 21:15:35,712 - INFO - PROGRESS: at sentence #70000, processed 3221842 words, keeping 479780 word types\n",
                        "2025-11-26 21:15:35,881 - INFO - PROGRESS: at sentence #80000, processed 3679701 words, keeping 513997 word types\n",
                        "2025-11-26 21:15:36,086 - INFO - PROGRESS: at sentence #90000, processed 4141449 words, keeping 544669 word types\n",
                        "2025-11-26 21:15:36,266 - INFO - PROGRESS: at sentence #100000, processed 4599508 words, keeping 572907 word types\n",
                        "2025-11-26 21:15:36,450 - INFO - PROGRESS: at sentence #110000, processed 5053957 words, keeping 601477 word types\n",
                        "2025-11-26 21:15:36,546 - INFO - collected 615138 word types from a corpus of 5285840 raw words and 115040 sentences\n",
                        "2025-11-26 21:15:36,548 - INFO - Creating a fresh vocabulary\n",
                        "2025-11-26 21:15:37,516 - INFO - Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 316109 unique words (51.39% of original 615138, drops 299029)', 'datetime': '2025-11-26T21:15:37.516205', 'gensim': '4.4.0', 'python': '3.13.7 | packaged by Anaconda, Inc. | (main, Sep  9 2025, 19:54:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
                        "2025-11-26 21:15:37,517 - INFO - Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 4986811 word corpus (94.34% of original 5285840, drops 299029)', 'datetime': '2025-11-26T21:15:37.517101', 'gensim': '4.4.0', 'python': '3.13.7 | packaged by Anaconda, Inc. | (main, Sep  9 2025, 19:54:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
                        "2025-11-26 21:15:38,869 - INFO - deleting the raw counts dictionary of 615138 items\n",
                        "2025-11-26 21:15:38,896 - INFO - sample=0.001 downsamples 0 most-common words\n",
                        "2025-11-26 21:15:38,897 - INFO - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4986811 word corpus (100.0%% of prior 4986811)', 'datetime': '2025-11-26T21:15:38.897657', 'gensim': '4.4.0', 'python': '3.13.7 | packaged by Anaconda, Inc. | (main, Sep  9 2025, 19:54:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
                        "2025-11-26 21:15:41,272 - INFO - estimated required memory for 316109 words and 128 dimensions: 481750116 bytes\n",
                        "2025-11-26 21:15:41,274 - INFO - resetting layer weights\n",
                        "2025-11-26 21:15:41,593 - INFO - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-11-26T21:15:41.593749', 'gensim': '4.4.0', 'python': '3.13.7 | packaged by Anaconda, Inc. | (main, Sep  9 2025, 19:54:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'}\n",
                        "2025-11-26 21:15:41,594 - INFO -    - Vocabulary ÌÅ¨Í∏∞: 316,109Í∞ú Í≥°\n",
                        "2025-11-26 21:15:41,595 - INFO - \n",
                        "üî• Î™®Îç∏ ÌïôÏäµ Ï§ë...\n",
                        "2025-11-26 21:15:41,597 - INFO - Word2Vec lifecycle event {'msg': 'training model with 16 workers on 316109 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2025-11-26T21:15:41.597342', 'gensim': '4.4.0', 'python': '3.13.7 | packaged by Anaconda, Inc. | (main, Sep  9 2025, 19:54:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
                        "2025-11-26 21:15:42,932 - INFO - EPOCH 0 - PROGRESS: at 0.18% examples, 8251 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:15:44,030 - INFO - EPOCH 0 - PROGRESS: at 0.78% examples, 16344 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:15:45,044 - INFO - EPOCH 0 - PROGRESS: at 3.85% examples, 56323 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:15:46,169 - INFO - EPOCH 0 - PROGRESS: at 6.45% examples, 71656 words/s, in_qsize 32, out_qsize 1\n",
                        "2025-11-26 21:15:47,240 - INFO - EPOCH 0 - PROGRESS: at 9.27% examples, 83451 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:15:48,489 - INFO - EPOCH 0 - PROGRESS: at 12.45% examples, 91681 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:15:49,597 - INFO - EPOCH 0 - PROGRESS: at 15.45% examples, 97802 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:15:50,656 - INFO - EPOCH 0 - PROGRESS: at 18.13% examples, 100944 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:15:51,681 - INFO - EPOCH 0 - PROGRESS: at 21.31% examples, 106568 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:15:52,712 - INFO - EPOCH 0 - PROGRESS: at 24.33% examples, 110311 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:15:53,810 - INFO - EPOCH 0 - PROGRESS: at 27.54% examples, 113489 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:15:54,974 - INFO - EPOCH 0 - PROGRESS: at 30.88% examples, 116214 words/s, in_qsize 30, out_qsize 6\n",
                        "2025-11-26 21:15:55,979 - INFO - EPOCH 0 - PROGRESS: at 34.01% examples, 119210 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:15:57,020 - INFO - EPOCH 0 - PROGRESS: at 36.87% examples, 120362 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:15:58,056 - INFO - EPOCH 0 - PROGRESS: at 39.37% examples, 120246 words/s, in_qsize 31, out_qsize 4\n",
                        "2025-11-26 21:15:59,132 - INFO - EPOCH 0 - PROGRESS: at 42.35% examples, 121427 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:16:00,210 - INFO - EPOCH 0 - PROGRESS: at 44.73% examples, 120984 words/s, in_qsize 32, out_qsize 1\n",
                        "2025-11-26 21:16:01,231 - INFO - EPOCH 0 - PROGRESS: at 47.86% examples, 122871 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:02,352 - INFO - EPOCH 0 - PROGRESS: at 50.44% examples, 122572 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:03,390 - INFO - EPOCH 0 - PROGRESS: at 53.53% examples, 123584 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:16:04,537 - INFO - EPOCH 0 - PROGRESS: at 56.01% examples, 122692 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:05,697 - INFO - EPOCH 0 - PROGRESS: at 59.26% examples, 123424 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:06,760 - INFO - EPOCH 0 - PROGRESS: at 61.85% examples, 123406 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:16:07,761 - INFO - EPOCH 0 - PROGRESS: at 64.85% examples, 124426 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:16:08,842 - INFO - EPOCH 0 - PROGRESS: at 68.08% examples, 125347 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:09,913 - INFO - EPOCH 0 - PROGRESS: at 71.51% examples, 126575 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:10,944 - INFO - EPOCH 0 - PROGRESS: at 74.35% examples, 126940 words/s, in_qsize 30, out_qsize 1\n",
                        "2025-11-26 21:16:11,974 - INFO - EPOCH 0 - PROGRESS: at 76.58% examples, 126365 words/s, in_qsize 31, out_qsize 2\n",
                        "2025-11-26 21:16:13,061 - INFO - EPOCH 0 - PROGRESS: at 78.78% examples, 125591 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:14,138 - INFO - EPOCH 0 - PROGRESS: at 81.25% examples, 125165 words/s, in_qsize 30, out_qsize 1\n",
                        "2025-11-26 21:16:15,168 - INFO - EPOCH 0 - PROGRESS: at 84.07% examples, 125536 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:16,233 - INFO - EPOCH 0 - PROGRESS: at 86.55% examples, 125211 words/s, in_qsize 32, out_qsize 1\n",
                        "2025-11-26 21:16:17,448 - INFO - EPOCH 0 - PROGRESS: at 88.82% examples, 124110 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:18,448 - INFO - EPOCH 0 - PROGRESS: at 91.51% examples, 124301 words/s, in_qsize 29, out_qsize 1\n",
                        "2025-11-26 21:16:19,601 - INFO - EPOCH 0 - PROGRESS: at 94.39% examples, 124232 words/s, in_qsize 30, out_qsize 0\n",
                        "2025-11-26 21:16:20,727 - INFO - EPOCH 0 - PROGRESS: at 97.57% examples, 124718 words/s, in_qsize 13, out_qsize 1\n",
                        "2025-11-26 21:16:21,157 - INFO - EPOCH 0: training on 5285840 raw words (4986811 effective words) took 39.4s, 126426 effective words/s\n",
                        "2025-11-26 21:16:22,225 - INFO - EPOCH 1 - PROGRESS: at 1.34% examples, 63960 words/s, in_qsize 29, out_qsize 2\n",
                        "2025-11-26 21:16:23,231 - INFO - EPOCH 1 - PROGRESS: at 5.13% examples, 124962 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:24,256 - INFO - EPOCH 1 - PROGRESS: at 8.33% examples, 135508 words/s, in_qsize 32, out_qsize 1\n",
                        "2025-11-26 21:16:25,412 - INFO - EPOCH 1 - PROGRESS: at 11.18% examples, 131901 words/s, in_qsize 30, out_qsize 1\n",
                        "2025-11-26 21:16:26,451 - INFO - EPOCH 1 - PROGRESS: at 14.53% examples, 137939 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:16:27,605 - INFO - EPOCH 1 - PROGRESS: at 17.72% examples, 137984 words/s, in_qsize 30, out_qsize 1\n",
                        "2025-11-26 21:16:28,617 - INFO - EPOCH 1 - PROGRESS: at 21.12% examples, 141996 words/s, in_qsize 30, out_qsize 2\n",
                        "2025-11-26 21:16:29,681 - INFO - EPOCH 1 - PROGRESS: at 24.17% examples, 141973 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:16:30,719 - INFO - EPOCH 1 - PROGRESS: at 27.53% examples, 144204 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:31,813 - INFO - EPOCH 1 - PROGRESS: at 30.51% examples, 143450 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:16:32,831 - INFO - EPOCH 1 - PROGRESS: at 33.68% examples, 144674 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:16:33,836 - INFO - EPOCH 1 - PROGRESS: at 36.48% examples, 144344 words/s, in_qsize 30, out_qsize 2\n",
                        "2025-11-26 21:16:34,936 - INFO - EPOCH 1 - PROGRESS: at 39.89% examples, 145096 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:35,953 - INFO - EPOCH 1 - PROGRESS: at 43.25% examples, 146575 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:37,100 - INFO - EPOCH 1 - PROGRESS: at 46.41% examples, 146089 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:38,204 - INFO - EPOCH 1 - PROGRESS: at 49.71% examples, 146545 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:39,228 - INFO - EPOCH 1 - PROGRESS: at 52.56% examples, 146006 words/s, in_qsize 29, out_qsize 2\n",
                        "2025-11-26 21:16:40,368 - INFO - EPOCH 1 - PROGRESS: at 56.19% examples, 146613 words/s, in_qsize 30, out_qsize 2\n",
                        "2025-11-26 21:16:41,376 - INFO - EPOCH 1 - PROGRESS: at 59.22% examples, 146729 words/s, in_qsize 32, out_qsize 1\n",
                        "2025-11-26 21:16:42,398 - INFO - EPOCH 1 - PROGRESS: at 62.60% examples, 147611 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:16:43,447 - INFO - EPOCH 1 - PROGRESS: at 65.64% examples, 147386 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:44,474 - INFO - EPOCH 1 - PROGRESS: at 68.30% examples, 146526 words/s, in_qsize 32, out_qsize 1\n",
                        "2025-11-26 21:16:45,620 - INFO - EPOCH 1 - PROGRESS: at 71.93% examples, 146946 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:16:46,704 - INFO - EPOCH 1 - PROGRESS: at 75.09% examples, 146975 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:47,716 - INFO - EPOCH 1 - PROGRESS: at 78.05% examples, 147052 words/s, in_qsize 30, out_qsize 1\n",
                        "2025-11-26 21:16:48,782 - INFO - EPOCH 1 - PROGRESS: at 81.41% examples, 147481 words/s, in_qsize 29, out_qsize 2\n",
                        "2025-11-26 21:16:49,822 - INFO - EPOCH 1 - PROGRESS: at 85.22% examples, 148723 words/s, in_qsize 32, out_qsize 2\n",
                        "2025-11-26 21:16:50,841 - INFO - EPOCH 1 - PROGRESS: at 88.07% examples, 148368 words/s, in_qsize 32, out_qsize 1\n",
                        "2025-11-26 21:16:51,845 - INFO - EPOCH 1 - PROGRESS: at 90.33% examples, 147179 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:16:52,853 - INFO - EPOCH 1 - PROGRESS: at 93.43% examples, 147221 words/s, in_qsize 32, out_qsize 2\n",
                        "2025-11-26 21:16:53,880 - INFO - EPOCH 1 - PROGRESS: at 97.19% examples, 148332 words/s, in_qsize 15, out_qsize 1\n",
                        "2025-11-26 21:16:54,553 - INFO - EPOCH 1: training on 5285840 raw words (4986811 effective words) took 33.4s, 149522 effective words/s\n",
                        "2025-11-26 21:16:55,597 - INFO - EPOCH 2 - PROGRESS: at 0.40% examples, 18572 words/s, in_qsize 32, out_qsize 3\n",
                        "2025-11-26 21:16:56,666 - INFO - EPOCH 2 - PROGRESS: at 4.61% examples, 108000 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:16:57,696 - INFO - EPOCH 2 - PROGRESS: at 7.75% examples, 123695 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:16:58,772 - INFO - EPOCH 2 - PROGRESS: at 11.17% examples, 132424 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:16:59,812 - INFO - EPOCH 2 - PROGRESS: at 14.90% examples, 141982 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:00,815 - INFO - EPOCH 2 - PROGRESS: at 18.12% examples, 144755 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:02,154 - INFO - EPOCH 2 - PROGRESS: at 21.30% examples, 140280 words/s, in_qsize 29, out_qsize 4\n",
                        "2025-11-26 21:17:03,157 - INFO - EPOCH 2 - PROGRESS: at 24.34% examples, 141419 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:04,170 - INFO - EPOCH 2 - PROGRESS: at 27.72% examples, 144095 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:05,205 - INFO - EPOCH 2 - PROGRESS: at 30.31% examples, 142391 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:06,248 - INFO - EPOCH 2 - PROGRESS: at 33.46% examples, 143410 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:07,267 - INFO - EPOCH 2 - PROGRESS: at 36.29% examples, 143012 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:08,307 - INFO - EPOCH 2 - PROGRESS: at 39.52% examples, 143795 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:09,327 - INFO - EPOCH 2 - PROGRESS: at 42.49% examples, 144081 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:10,452 - INFO - EPOCH 2 - PROGRESS: at 45.27% examples, 142771 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:11,459 - INFO - EPOCH 2 - PROGRESS: at 47.85% examples, 142061 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:12,483 - INFO - EPOCH 2 - PROGRESS: at 50.65% examples, 141805 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:13,569 - INFO - EPOCH 2 - PROGRESS: at 53.88% examples, 142081 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:14,597 - INFO - EPOCH 2 - PROGRESS: at 57.08% examples, 142723 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:15,644 - INFO - EPOCH 2 - PROGRESS: at 59.64% examples, 141420 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:16,760 - INFO - EPOCH 2 - PROGRESS: at 62.59% examples, 141040 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:17,793 - INFO - EPOCH 2 - PROGRESS: at 65.60% examples, 141240 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:18,797 - INFO - EPOCH 2 - PROGRESS: at 68.65% examples, 141586 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:19,821 - INFO - EPOCH 2 - PROGRESS: at 71.74% examples, 141789 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:20,837 - INFO - EPOCH 2 - PROGRESS: at 75.09% examples, 142756 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:21,955 - INFO - EPOCH 2 - PROGRESS: at 78.05% examples, 142432 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:23,008 - INFO - EPOCH 2 - PROGRESS: at 81.61% examples, 143414 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:24,040 - INFO - EPOCH 2 - PROGRESS: at 84.62% examples, 143519 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:25,093 - INFO - EPOCH 2 - PROGRESS: at 87.89% examples, 143815 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:26,097 - INFO - EPOCH 2 - PROGRESS: at 91.48% examples, 144894 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:27,140 - INFO - EPOCH 2 - PROGRESS: at 93.81% examples, 143695 words/s, in_qsize 29, out_qsize 3\n",
                        "2025-11-26 21:17:28,164 - INFO - EPOCH 2 - PROGRESS: at 96.64% examples, 143507 words/s, in_qsize 15, out_qsize 4\n",
                        "2025-11-26 21:17:28,813 - INFO - EPOCH 2: training on 5285840 raw words (4986811 effective words) took 34.2s, 145676 effective words/s\n",
                        "2025-11-26 21:17:29,895 - INFO - EPOCH 3 - PROGRESS: at 1.95% examples, 90637 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:30,927 - INFO - EPOCH 3 - PROGRESS: at 5.51% examples, 131257 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:31,982 - INFO - EPOCH 3 - PROGRESS: at 8.89% examples, 141246 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:33,059 - INFO - EPOCH 3 - PROGRESS: at 12.27% examples, 145350 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:34,104 - INFO - EPOCH 3 - PROGRESS: at 15.26% examples, 145053 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:35,106 - INFO - EPOCH 3 - PROGRESS: at 18.71% examples, 148827 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:36,107 - INFO - EPOCH 3 - PROGRESS: at 21.69% examples, 149047 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:37,173 - INFO - EPOCH 3 - PROGRESS: at 25.30% examples, 151459 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:38,221 - INFO - EPOCH 3 - PROGRESS: at 28.28% examples, 150483 words/s, in_qsize 30, out_qsize 1\n",
                        "2025-11-26 21:17:39,241 - INFO - EPOCH 3 - PROGRESS: at 31.62% examples, 151950 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:40,279 - INFO - EPOCH 3 - PROGRESS: at 34.76% examples, 152152 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:41,330 - INFO - EPOCH 3 - PROGRESS: at 38.01% examples, 152198 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:42,354 - INFO - EPOCH 3 - PROGRESS: at 41.23% examples, 152484 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:43,681 - INFO - EPOCH 3 - PROGRESS: at 44.69% examples, 150902 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:44,702 - INFO - EPOCH 3 - PROGRESS: at 48.04% examples, 151877 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:45,774 - INFO - EPOCH 3 - PROGRESS: at 51.40% examples, 152250 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:46,839 - INFO - EPOCH 3 - PROGRESS: at 55.21% examples, 153627 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:47,938 - INFO - EPOCH 3 - PROGRESS: at 58.69% examples, 153618 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:48,966 - INFO - EPOCH 3 - PROGRESS: at 62.05% examples, 154133 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:49,993 - INFO - EPOCH 3 - PROGRESS: at 65.60% examples, 155084 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:51,117 - INFO - EPOCH 3 - PROGRESS: at 69.42% examples, 155687 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:52,136 - INFO - EPOCH 3 - PROGRESS: at 73.01% examples, 156539 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:53,326 - INFO - EPOCH 3 - PROGRESS: at 76.41% examples, 155858 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:17:54,475 - INFO - EPOCH 3 - PROGRESS: at 80.09% examples, 156210 words/s, in_qsize 28, out_qsize 3\n",
                        "2025-11-26 21:17:55,484 - INFO - EPOCH 3 - PROGRESS: at 83.69% examples, 156994 words/s, in_qsize 30, out_qsize 1\n",
                        "2025-11-26 21:17:56,497 - INFO - EPOCH 3 - PROGRESS: at 86.74% examples, 156693 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:57,509 - INFO - EPOCH 3 - PROGRESS: at 89.54% examples, 156081 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:58,546 - INFO - EPOCH 3 - PROGRESS: at 92.05% examples, 154717 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:17:59,576 - INFO - EPOCH 3 - PROGRESS: at 95.33% examples, 154726 words/s, in_qsize 25, out_qsize 0\n",
                        "2025-11-26 21:18:00,601 - INFO - EPOCH 3 - PROGRESS: at 99.25% examples, 155923 words/s, in_qsize 4, out_qsize 1\n",
                        "2025-11-26 21:18:00,675 - INFO - EPOCH 3: training on 5285840 raw words (4986811 effective words) took 31.8s, 156706 effective words/s\n",
                        "2025-11-26 21:18:01,714 - INFO - EPOCH 4 - PROGRESS: at 1.35% examples, 64217 words/s, in_qsize 32, out_qsize 1\n",
                        "2025-11-26 21:18:02,825 - INFO - EPOCH 4 - PROGRESS: at 4.61% examples, 105368 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:18:03,849 - INFO - EPOCH 4 - PROGRESS: at 7.76% examples, 121908 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:18:04,860 - INFO - EPOCH 4 - PROGRESS: at 10.57% examples, 126325 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:18:06,021 - INFO - EPOCH 4 - PROGRESS: at 13.56% examples, 127046 words/s, in_qsize 32, out_qsize 1\n",
                        "2025-11-26 21:18:07,034 - INFO - EPOCH 4 - PROGRESS: at 17.16% examples, 134833 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:18:08,106 - INFO - EPOCH 4 - PROGRESS: at 20.37% examples, 136870 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:18:09,138 - INFO - EPOCH 4 - PROGRESS: at 23.19% examples, 136866 words/s, in_qsize 31, out_qsize 2\n",
                        "2025-11-26 21:18:10,196 - INFO - EPOCH 4 - PROGRESS: at 26.42% examples, 138472 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:18:11,232 - INFO - EPOCH 4 - PROGRESS: at 29.19% examples, 138153 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:18:12,259 - INFO - EPOCH 4 - PROGRESS: at 32.34% examples, 139730 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:18:13,270 - INFO - EPOCH 4 - PROGRESS: at 35.13% examples, 139675 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:18:14,327 - INFO - EPOCH 4 - PROGRESS: at 38.41% examples, 140617 words/s, in_qsize 31, out_qsize 1\n",
                        "2025-11-26 21:18:15,328 - INFO - EPOCH 4 - PROGRESS: at 41.76% examples, 142554 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:18:16,433 - INFO - EPOCH 4 - PROGRESS: at 45.29% examples, 143926 words/s, in_qsize 32, out_qsize 1\n",
                        "2025-11-26 21:18:17,480 - INFO - EPOCH 4 - PROGRESS: at 48.98% examples, 146146 words/s, in_qsize 31, out_qsize 2\n",
                        "2025-11-26 21:18:18,571 - INFO - EPOCH 4 - PROGRESS: at 52.75% examples, 147714 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:18:19,646 - INFO - EPOCH 4 - PROGRESS: at 56.52% examples, 149202 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:18:20,674 - INFO - EPOCH 4 - PROGRESS: at 59.96% examples, 149993 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:18:21,757 - INFO - EPOCH 4 - PROGRESS: at 63.73% examples, 151145 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:18:22,779 - INFO - EPOCH 4 - PROGRESS: at 67.49% examples, 152667 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:18:23,877 - INFO - EPOCH 4 - PROGRESS: at 71.11% examples, 153124 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:18:24,984 - INFO - EPOCH 4 - PROGRESS: at 74.92% examples, 153895 words/s, in_qsize 31, out_qsize 0\n",
                        "2025-11-26 21:18:26,058 - INFO - EPOCH 4 - PROGRESS: at 78.26% examples, 154050 words/s, in_qsize 29, out_qsize 3\n",
                        "2025-11-26 21:18:27,092 - INFO - EPOCH 4 - PROGRESS: at 82.39% examples, 155849 words/s, in_qsize 32, out_qsize 0\n",
                        "2025-11-26 21:18:28,150 - INFO - EPOCH 4 - PROGRESS: at 85.98% examples, 156382 words/s, in_qsize 32, out_qsize 1\n",
                        "2025-11-26 21:18:29,173 - INFO - EPOCH 4 - PROGRESS: at 89.52% examples, 157015 words/s, in_qsize 32, out_qsize 2\n",
                        "2025-11-26 21:18:30,232 - INFO - EPOCH 4 - PROGRESS: at 93.63% examples, 158052 words/s, in_qsize 32, out_qsize 1\n",
                        "2025-11-26 21:18:31,472 - INFO - EPOCH 4 - PROGRESS: at 97.59% examples, 158074 words/s, in_qsize 13, out_qsize 1\n",
                        "2025-11-26 21:18:31,918 - INFO - EPOCH 4: training on 5285840 raw words (4986811 effective words) took 31.2s, 159683 effective words/s\n",
                        "2025-11-26 21:18:31,922 - INFO - Word2Vec lifecycle event {'msg': 'training on 26429200 raw words (24934055 effective words) took 170.3s, 146394 effective words/s', 'datetime': '2025-11-26T21:18:31.921696', 'gensim': '4.4.0', 'python': '3.13.7 | packaged by Anaconda, Inc. | (main, Sep  9 2025, 19:54:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
                        "2025-11-26 21:18:31,923 - INFO - \n",
                        "‚úÖ item2vec ÌïôÏäµ ÏôÑÎ£å!\n",
                        "2025-11-26 21:18:31,924 - INFO -    - ÏµúÏ¢Ö Vocabulary ÌÅ¨Í∏∞: 316,109Í∞ú Í≥°\n",
                        "2025-11-26 21:18:32,179 - INFO - \n",
                        "üìä ÌïôÏäµ Í≤∞Í≥º ÏöîÏïΩ:\n",
                        "2025-11-26 21:18:32,181 - INFO -    - Vocabulary ÌÅ¨Í∏∞: 316,109Í∞ú Í≥°\n",
                        "2025-11-26 21:18:32,182 - INFO -    - ÏûÑÎ≤†Îî© Ï∞®Ïõê: 128\n",
                        "2025-11-26 21:18:32,195 - INFO - \n",
                        "üéµ ÏòàÏãú Í≥° ÏûÑÎ≤†Îî©:\n",
                        "2025-11-26 21:18:32,201 - INFO -    - Song ID 144663: shape=(128,), norm=5.2741\n",
                        "2025-11-26 21:18:32,201 - INFO -    - Song ID 116573: shape=(128,), norm=4.7194\n",
                        "2025-11-26 21:18:32,202 - INFO -    - Song ID 357367: shape=(128,), norm=5.5093\n",
                        "2025-11-26 21:18:32,203 - INFO - \n",
                        "‚úÖ Step 4 ÏôÑÎ£å: Î™®Îç∏ ÌïôÏäµ Ïã§Ìñâ ÏôÑÎ£å\n"
                    ]
                }
            ],
            "source": [
                "# Step 4: item2vec ÌïôÏäµ Ïã§Ìñâ\n",
                "# Ïã§Ï†úÎ°ú Î™®Îç∏ÏùÑ ÌïôÏäµÏãúÌÇµÎãàÎã§ (ÏãúÍ∞ÑÏù¥ Îã§ÏÜå Í±∏Î¶¥ Ïàò ÏûàÏäµÎãàÎã§)\n",
                "\n",
                "logger.info(\"\\n\" + \"=\"*60)\n",
                "logger.info(\"Step 4: item2vec Î™®Îç∏ ÌïôÏäµ Ïã§Ìñâ\")\n",
                "logger.info(\"=\"*60)\n",
                "\n",
                "# PlaylistSentenceIterator ÏÉùÏÑ±\n",
                "sentences = PlaylistSentenceIterator(train_data, min_len=2)\n",
                "\n",
                "# item2vec ÌïôÏäµ Ïã§Ìñâ\n",
                "w2v_model = train_item2vec(sentences, HYPERPARAMS)\n",
                "\n",
                "# ========================================\n",
                "# ÌïôÏäµ Í≤∞Í≥º ÌôïÏù∏\n",
                "# ========================================\n",
                "logger.info(\"\\nüìä ÌïôÏäµ Í≤∞Í≥º ÏöîÏïΩ:\")\n",
                "logger.info(f\"   - Vocabulary ÌÅ¨Í∏∞: {len(w2v_model.wv):,}Í∞ú Í≥°\")\n",
                "logger.info(f\"   - ÏûÑÎ≤†Îî© Ï∞®Ïõê: {w2v_model.wv.vector_size}\")\n",
                "\n",
                "# ÏòàÏãú Í≥° Î≤°ÌÑ∞ ÌôïÏù∏\n",
                "sample_songs = list(w2v_model.wv.index_to_key)[:3]\n",
                "logger.info(\"\\nüéµ ÏòàÏãú Í≥° ÏûÑÎ≤†Îî©:\")\n",
                "for song_id in sample_songs:\n",
                "    vector = w2v_model.wv[song_id]\n",
                "    logger.info(f\"   - Song ID {song_id}: shape={vector.shape}, norm={np.linalg.norm(vector):.4f}\")\n",
                "\n",
                "logger.info(\"\\n‚úÖ Step 4 ÏôÑÎ£å: Î™®Îç∏ ÌïôÏäµ Ïã§Ìñâ ÏôÑÎ£å\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-11-26 21:42:24,326 - INFO - \n",
                        "============================================================\n",
                        "2025-11-26 21:42:24,328 - INFO - Step 5: Î™®Îç∏ Ï†ÄÏû• Î∞è Î°úÎìú\n",
                        "2025-11-26 21:42:24,329 - INFO - ============================================================\n",
                        "2025-11-26 21:42:24,331 - INFO - \n",
                        "üíæ Î™®Îç∏ Ï†ÄÏû• Ï§ë: ./models\\v2_item2vec.model\n",
                        "2025-11-26 21:42:24,339 - INFO - Word2Vec lifecycle event {'fname_or_handle': './models\\\\v2_item2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-11-26T21:42:24.339164', 'gensim': '4.4.0', 'python': '3.13.7 | packaged by Anaconda, Inc. | (main, Sep  9 2025, 19:54:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'saving'}\n",
                        "2025-11-26 21:42:24,353 - INFO - storing np array 'vectors' to ./models\\v2_item2vec.model.wv.vectors.npy\n",
                        "2025-11-26 21:42:24,822 - INFO - storing np array 'syn1neg' to ./models\\v2_item2vec.model.syn1neg.npy\n",
                        "2025-11-26 21:42:25,662 - INFO - not storing attribute cum_table\n",
                        "2025-11-26 21:42:26,516 - INFO - saved ./models\\v2_item2vec.model\n",
                        "2025-11-26 21:42:26,519 - INFO - ‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å\n",
                        "2025-11-26 21:42:26,520 - INFO - \n",
                        "üìÇ Î™®Îç∏ Î°úÎìú ÌÖåÏä§Ìä∏: ./models\\v2_item2vec.model\n",
                        "2025-11-26 21:42:26,522 - INFO - loading Word2Vec object from ./models\\v2_item2vec.model\n",
                        "2025-11-26 21:42:26,997 - INFO - loading wv recursively from ./models\\v2_item2vec.model.wv.* with mmap=None\n",
                        "2025-11-26 21:42:26,998 - INFO - loading vectors from ./models\\v2_item2vec.model.wv.vectors.npy with mmap=None\n",
                        "2025-11-26 21:42:27,324 - INFO - loading syn1neg from ./models\\v2_item2vec.model.syn1neg.npy with mmap=None\n",
                        "2025-11-26 21:42:27,757 - INFO - setting ignored attribute cum_table to None\n",
                        "2025-11-26 21:42:29,945 - INFO - Word2Vec lifecycle event {'fname': './models\\\\v2_item2vec.model', 'datetime': '2025-11-26T21:42:29.945376', 'gensim': '4.4.0', 'python': '3.13.7 | packaged by Anaconda, Inc. | (main, Sep  9 2025, 19:54:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'}\n",
                        "2025-11-26 21:42:29,948 - INFO - ‚úÖ Î™®Îç∏ Î°úÎìú ÏôÑÎ£å\n",
                        "2025-11-26 21:42:29,949 - INFO - \n",
                        "üîç Î°úÎìúÎêú Î™®Îç∏ Í≤ÄÏ¶ù:\n",
                        "2025-11-26 21:42:29,950 - INFO -    - Vocabulary ÌÅ¨Í∏∞: 316,109Í∞ú Í≥°\n",
                        "2025-11-26 21:42:29,951 - INFO -    - ÏûÑÎ≤†Îî© Ï∞®Ïõê: 128\n",
                        "2025-11-26 21:42:29,968 - INFO - \n",
                        "‚úîÔ∏è  Î≤°ÌÑ∞ ÏùºÏπò ÌôïÏù∏ (Ï∞®Ïù¥ norm): 0.0000000000\n",
                        "2025-11-26 21:42:29,969 - INFO -    ‚úÖ Ï†ÄÏû•/Î°úÎìúÍ∞Ä Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÎèôÏûëÌï©ÎãàÎã§!\n",
                        "2025-11-26 21:42:29,970 - INFO - \n",
                        "‚úÖ Step 5 ÏôÑÎ£å: Î™®Îç∏ Ï†ÄÏû•/Î°úÎìú ÌÖåÏä§Ìä∏ ÏôÑÎ£å\n"
                    ]
                }
            ],
            "source": [
                "# Step 5: Î™®Îç∏ Ï†ÄÏû•/Î°úÎìú\n",
                "# ÌïôÏäµÎêú Î™®Îç∏ÏùÑ Ï†ÄÏû•ÌïòÍ≥†, Î°úÎìúÌïòÎäî Î∞©Î≤ïÏùÑ ÌôïÏù∏Ìï©ÎãàÎã§\n",
                "\n",
                "logger.info(\"\\n\" + \"=\"*60)\n",
                "logger.info(\"Step 5: Î™®Îç∏ Ï†ÄÏû• Î∞è Î°úÎìú\")\n",
                "logger.info(\"=\"*60)\n",
                "\n",
                "# ========================================\n",
                "# Î™®Îç∏ Ï†ÄÏû•\n",
                "# ========================================\n",
                "model_path = os.path.join(MODEL_DIR, \"v2_item2vec.model\")\n",
                "logger.info(f\"\\nüíæ Î™®Îç∏ Ï†ÄÏû• Ï§ë: {model_path}\")\n",
                "\n",
                "w2v_model.save(model_path)\n",
                "logger.info(\"‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å\")\n",
                "\n",
                "# ========================================\n",
                "# Î™®Îç∏ Î°úÎìú ÌÖåÏä§Ìä∏\n",
                "# ========================================\n",
                "logger.info(f\"\\nüìÇ Î™®Îç∏ Î°úÎìú ÌÖåÏä§Ìä∏: {model_path}\")\n",
                "loaded_model = Word2Vec.load(model_path)\n",
                "logger.info(\"‚úÖ Î™®Îç∏ Î°úÎìú ÏôÑÎ£å\")\n",
                "\n",
                "# Î°úÎìúÎêú Î™®Îç∏ Í≤ÄÏ¶ù\n",
                "logger.info(\"\\nüîç Î°úÎìúÎêú Î™®Îç∏ Í≤ÄÏ¶ù:\")\n",
                "logger.info(f\"   - Vocabulary ÌÅ¨Í∏∞: {len(loaded_model.wv):,}Í∞ú Í≥°\")\n",
                "logger.info(f\"   - ÏûÑÎ≤†Îî© Ï∞®Ïõê: {loaded_model.wv.vector_size}\")\n",
                "\n",
                "# ÏõêÎ≥∏ Î™®Îç∏Í≥º Î°úÎìúÎêú Î™®Îç∏Ïùò Î≤°ÌÑ∞ ÎπÑÍµê\n",
                "test_song_id = list(w2v_model.wv.index_to_key)[0]\n",
                "original_vector = w2v_model.wv[test_song_id]\n",
                "loaded_vector = loaded_model.wv[test_song_id]\n",
                "\n",
                "vector_diff = np.linalg.norm(original_vector - loaded_vector)\n",
                "logger.info(f\"\\n‚úîÔ∏è  Î≤°ÌÑ∞ ÏùºÏπò ÌôïÏù∏ (Ï∞®Ïù¥ norm): {vector_diff:.10f}\")\n",
                "if vector_diff < 1e-6:\n",
                "    logger.info(\"   ‚úÖ Ï†ÄÏû•/Î°úÎìúÍ∞Ä Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÎèôÏûëÌï©ÎãàÎã§!\")\n",
                "else:\n",
                "    logger.warning(\"   ‚ö†Ô∏è  Î≤°ÌÑ∞ Ï∞®Ïù¥Í∞Ä Í∞êÏßÄÎêòÏóàÏäµÎãàÎã§.\")\n",
                "\n",
                "logger.info(\"\\n‚úÖ Step 5 ÏôÑÎ£å: Î™®Îç∏ Ï†ÄÏû•/Î°úÎìú ÌÖåÏä§Ìä∏ ÏôÑÎ£å\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "Step 6: Ïú†ÏÇ¨ Í≥° Ï∂îÏ≤ú Ìï®Ïàò Ï†ïÏùò Î∞è ÌÖåÏä§Ìä∏\n",
                        "============================================================\n",
                        "\n",
                        "üéØ ÏãúÎìú Í≥° ID: 525514\n",
                        "\n",
                        "üéµ Ï∂îÏ≤ú Í≤∞Í≥º (Top 10):\n",
                        "   ÏàúÏúÑ | Song ID    | Ïú†ÏÇ¨ÎèÑ\n",
                        "   -----------------------------------\n",
                        "    1   |     695342 | 0.9845\n",
                        "    2   |     658448 | 0.9788\n",
                        "    3   |     423887 | 0.9784\n",
                        "    4   |      15811 | 0.9753\n",
                        "    5   |     552048 | 0.9753\n",
                        "    6   |     108392 | 0.9738\n",
                        "    7   |     650362 | 0.9736\n",
                        "    8   |     487399 | 0.9734\n",
                        "    9   |     200922 | 0.9732\n",
                        "   10   |     343991 | 0.9730\n",
                        "\n",
                        "‚úÖ Step 6 ÏôÑÎ£å: Ïú†ÏÇ¨ Í≥° Ï∂îÏ≤ú Ìï®Ïàò Ï†ïÏùò Î∞è ÌÖåÏä§Ìä∏ ÏôÑÎ£å\n"
                    ]
                }
            ],
            "source": [
                "# Step 6: Ïú†ÏÇ¨ Í≥° Ï∂îÏ≤ú Ìï®Ïàò + ÏòàÏ†ú\n",
                "# ÌïôÏäµÎêú item2vec Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ïú†ÏÇ¨Ìïú Í≥°ÏùÑ Ï∂îÏ≤úÌïòÎäî Ìï®ÏàòÎ•º Ï†ïÏùòÌï©ÎãàÎã§\n",
                "\n",
                "# =========================================================\n",
                "# (Ï∂îÍ∞Ä) Ï†ÄÏû•Îêú Î™®Îç∏ Î°úÎìú Î°úÏßÅ\n",
                "# Ïª§ÎÑê Ïû¨ÏãúÏûë ÌõÑ Step 4(ÌïôÏäµ)Î•º Í±¥ÎÑàÎõ∞Í≥† Ïã§ÌñâÌï† Í≤ΩÏö∞Î•º ÏúÑÌï¥ Î™®Îç∏ÏùÑ Î°úÎìúÌï©ÎãàÎã§.\n",
                "# =========================================================\n",
                "if 'w2v_model' not in locals():\n",
                "    try:\n",
                "        # Step 0ÏùÑ Ïã§ÌñâÌñàÎã§Î©¥ MODEL_DIR, Word2Vec Îì±Ïù¥ Ï†ïÏùòÎêòÏñ¥ ÏûàÏñ¥Ïïº Ìï®\n",
                "        # ÎßåÏïΩ Ï†ïÏùòÎêòÏßÄ ÏïäÏïòÎã§Î©¥ ÏûÑÏãúÎ°ú import Î∞è ÏÑ§Ï†ï\n",
                "        if 'Word2Vec' not in locals():\n",
                "            from gensim.models import Word2Vec\n",
                "        if 'os' not in locals():\n",
                "            import os\n",
                "        if 'MODEL_DIR' not in locals():\n",
                "            MODEL_DIR = \"./models\"\n",
                "            \n",
                "        _model_path = \"C:/Users/ASUS/music_recommend/work/models/models/v2_item2vec.model\"\n",
                "        # os.path.join(MODEL_DIR, \"v2_item2vec.model\")\n",
                "        \n",
                "        if os.path.exists(_model_path):\n",
                "            if 'logger' in locals():\n",
                "                logger.info(f\"üîÑ Ï†ÄÏû•Îêú Î™®Îç∏ÏùÑ Î°úÎìúÌï©ÎãàÎã§: {_model_path}\")\n",
                "            else:\n",
                "                print(f\"üîÑ Ï†ÄÏû•Îêú Î™®Îç∏ÏùÑ Î°úÎìúÌï©ÎãàÎã§: {_model_path}\")\n",
                "                \n",
                "            w2v_model = Word2Vec.load(_model_path)\n",
                "            \n",
                "            if 'logger' in locals():\n",
                "                logger.info(\"‚úÖ Î™®Îç∏ Î°úÎìú ÏôÑÎ£å\")\n",
                "            else:\n",
                "                print(\"‚úÖ Î™®Îç∏ Î°úÎìú ÏôÑÎ£å\")\n",
                "        else:\n",
                "            msg = f\"‚ùå Î™®Îç∏ ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {_model_path}\"\n",
                "            if 'logger' in locals(): logger.warning(msg)\n",
                "            else: print(msg)\n",
                "            \n",
                "    except Exception as e:\n",
                "        msg = f\"‚ö†Ô∏è Î™®Îç∏ Î°úÎìú Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}\"\n",
                "        if 'logger' in locals(): logger.error(msg)\n",
                "        else: print(msg)\n",
                "\n",
                "def get_similar_songs(model, song_id, topn=20):\n",
                "    \"\"\"\n",
                "    Ï£ºÏñ¥ÏßÑ Í≥° IDÏôÄ Ïú†ÏÇ¨Ìïú Í≥°Îì§ÏùÑ Ï∂îÏ≤úÌï©ÎãàÎã§.\n",
                "    \n",
                "    Args:\n",
                "        model: ÌïôÏäµÎêú Word2Vec Î™®Îç∏\n",
                "        song_id: ÏãúÎìú Í≥° ID (int ÎòêÎäî str)\n",
                "        topn: Ï∂îÏ≤úÌï† Í≥° Í∞úÏàò\n",
                "    \n",
                "    Returns:\n",
                "        List[Tuple[int, float]]: [(song_id, similarity_score), ...] ÌòïÌÉúÏùò Î¶¨Ïä§Ìä∏\n",
                "    \"\"\"\n",
                "    # song_idÎ•º Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôò (Î™®Îç∏ÏóêÏÑú ÏÇ¨Ïö©ÌïòÎäî ÌÜ†ÌÅ∞ ÌòïÏãù)\n",
                "    song_id_str = str(song_id)\n",
                "    \n",
                "    # Î™®Îç∏Ïóê Ìï¥Îãπ Í≥°Ïù¥ ÏóÜÎäî Í≤ΩÏö∞\n",
                "    if song_id_str not in model.wv:\n",
                "        logger.warning(f\"‚ö†Ô∏è  Í≥° ID '{song_id}'Í∞Ä Î™®Îç∏Ïóê ÏóÜÏäµÎãàÎã§. (ÏµúÏÜå Ï∂úÌòÑ ÌöüÏàò ÎØ∏Îã¨ Í∞ÄÎä•ÏÑ±)\")\n",
                "        return []\n",
                "    \n",
                "    # gensimÏùò most_similar ÏÇ¨Ïö©\n",
                "    similar_items = model.wv.most_similar(song_id_str, topn=topn)\n",
                "    \n",
                "    # (str_id, similarity) -> (int_id, similarity) Î≥ÄÌôò\n",
                "    results = [(int(item_id), similarity) for item_id, similarity in similar_items]\n",
                "    \n",
                "    return results\n",
                "\n",
                "logger.info(\"\\n\" + \"=\"*60)\n",
                "logger.info(\"Step 6: Ïú†ÏÇ¨ Í≥° Ï∂îÏ≤ú Ìï®Ïàò Ï†ïÏùò Î∞è ÌÖåÏä§Ìä∏\")\n",
                "logger.info(\"=\"*60)\n",
                "\n",
                "# ========================================\n",
                "# Ï∂îÏ≤ú Ìï®Ïàò ÌÖåÏä§Ìä∏\n",
                "# ========================================\n",
                "# train.jsonÏóêÏÑú Ï†ÅÎãπÌïú seed_song ÏÑ†ÌÉù (Ï≤´ Î≤àÏß∏ ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏Ïùò Ï≤´ Í≥°)\n",
                "if 'train_data' in locals():\n",
                "    seed_song_id = train_data[0]['songs'][0]\n",
                "elif 'w2v_model' in locals():\n",
                "    seed_song_id = int(w2v_model.wv.index_to_key[0])\n",
                "    if 'logger' in locals(): logger.info(\"‚ö†Ô∏è train_dataÍ∞Ä Î©îÎ™®Î¶¨Ïóê ÏóÜÏñ¥ Î™®Îç∏Ïùò Ï≤´ Î≤àÏß∏ Í≥°ÏùÑ ÏãúÎìúÎ°ú ÏÇ¨Ïö©Ìï©ÎãàÎã§.\")\n",
                "else:\n",
                "    seed_song_id = 0\n",
                "\n",
                "logger.info(f\"\\nüéØ ÏãúÎìú Í≥° ID: {seed_song_id}\")\n",
                "\n",
                "# Ïú†ÏÇ¨ Í≥° Ï∂îÏ≤ú\n",
                "similar_songs = get_similar_songs(w2v_model, seed_song_id, topn=10)\n",
                "\n",
                "if similar_songs:\n",
                "    logger.info(f\"\\nüéµ Ï∂îÏ≤ú Í≤∞Í≥º (Top 10):\")\n",
                "    logger.info(\"   ÏàúÏúÑ | Song ID    | Ïú†ÏÇ¨ÎèÑ\")\n",
                "    logger.info(\"   \" + \"-\"*35)\n",
                "    for rank, (song_id, similarity) in enumerate(similar_songs, 1):\n",
                "        logger.info(f\"   {rank:2d}   | {song_id:10d} | {similarity:.4f}\")\n",
                "else:\n",
                "    logger.warning(\"   Ï∂îÏ≤ú Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§.\")\n",
                "\n",
                "# TODO: Ï∂îÌõÑ song_meta.jsonÏùÑ ÌôúÏö©ÌïòÏó¨ Í≥°Î™Ö, ÏïÑÌã∞Ïä§Ìä∏Î™Ö Îì± Î©îÌÉÄÎç∞Ïù¥ÌÑ∞Î•º Ìï®Íªò ÌëúÏãú ÏòàÏ†ï\n",
                "\n",
                "logger.info(\"\\n‚úÖ Step 6 ÏôÑÎ£å: Ïú†ÏÇ¨ Í≥° Ï∂îÏ≤ú Ìï®Ïàò Ï†ïÏùò Î∞è ÌÖåÏä§Ìä∏ ÏôÑÎ£å\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-11-26 21:43:50,686 - INFO - \n",
                        "============================================================\n",
                        "2025-11-26 21:43:50,688 - INFO - Step 7 (ÏÑ†ÌÉù): ÌèâÍ∞Ä Î∞è Ï≤¥Í∞ê ÌÖåÏä§Ìä∏\n",
                        "2025-11-26 21:43:50,689 - INFO - ============================================================\n",
                        "2025-11-26 21:43:50,690 - INFO - \n",
                        "üß™ ÌÖåÏä§Ìä∏ 1: ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ ÎÇ¥ Í≥° Ï∂îÏ≤ú Ïû¨ÌòÑÏú® ÌôïÏù∏\n",
                        "2025-11-26 21:43:50,691 - INFO -    (Í∞ôÏùÄ ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏Ïóê ÏûàÎçò Í≥°Ïù¥ Ï∂îÏ≤ú Í≤∞Í≥ºÏóê ÏñºÎßàÎÇò Ìè¨Ìï®ÎêòÎäîÏßÄ ÌôïÏù∏)\n",
                        "\n",
                        "2025-11-26 21:43:51,009 - INFO -    ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ 1:\n",
                        "2025-11-26 21:43:51,009 - INFO -       - ÏãúÎìú Í≥°: 525514\n",
                        "2025-11-26 21:43:51,010 - INFO -       - Ï†ïÎãµ Í≥° Ïàò: 18\n",
                        "2025-11-26 21:43:51,010 - INFO -       - Ï∂îÏ≤ú Í≥° Ï§ë Ï†ïÎãµ: 1Í∞ú\n",
                        "2025-11-26 21:43:51,011 - INFO -       - Ïû¨ÌòÑÏú®: 5.56%\n",
                        "\n",
                        "2025-11-26 21:43:51,021 - INFO -    ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ 2:\n",
                        "2025-11-26 21:43:51,022 - INFO -       - ÏãúÎìú Í≥°: 432406\n",
                        "2025-11-26 21:43:51,023 - INFO -       - Ï†ïÎãµ Í≥° Ïàò: 41\n",
                        "2025-11-26 21:43:51,023 - INFO -       - Ï∂îÏ≤ú Í≥° Ï§ë Ï†ïÎãµ: 0Í∞ú\n",
                        "2025-11-26 21:43:51,023 - INFO -       - Ïû¨ÌòÑÏú®: 0.00%\n",
                        "\n",
                        "2025-11-26 21:43:51,034 - INFO -    ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ 3:\n",
                        "2025-11-26 21:43:51,035 - INFO -       - ÏãúÎìú Í≥°: 83116\n",
                        "2025-11-26 21:43:51,035 - INFO -       - Ï†ïÎãµ Í≥° Ïàò: 27\n",
                        "2025-11-26 21:43:51,036 - INFO -       - Ï∂îÏ≤ú Í≥° Ï§ë Ï†ïÎãµ: 1Í∞ú\n",
                        "2025-11-26 21:43:51,036 - INFO -       - Ïû¨ÌòÑÏú®: 3.70%\n",
                        "\n",
                        "2025-11-26 21:43:51,046 - INFO -    ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ 4:\n",
                        "2025-11-26 21:43:51,047 - INFO -       - ÏãúÎìú Í≥°: 394031\n",
                        "2025-11-26 21:43:51,047 - INFO -       - Ï†ïÎãµ Í≥° Ïàò: 37\n",
                        "2025-11-26 21:43:51,047 - INFO -       - Ï∂îÏ≤ú Í≥° Ï§ë Ï†ïÎãµ: 1Í∞ú\n",
                        "2025-11-26 21:43:51,048 - INFO -       - Ïû¨ÌòÑÏú®: 2.70%\n",
                        "\n",
                        "2025-11-26 21:43:51,066 - INFO -    ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ 5:\n",
                        "2025-11-26 21:43:51,067 - INFO -       - ÏãúÎìú Í≥°: 159327\n",
                        "2025-11-26 21:43:51,068 - INFO -       - Ï†ïÎãµ Í≥° Ïàò: 52\n",
                        "2025-11-26 21:43:51,069 - INFO -       - Ï∂îÏ≤ú Í≥° Ï§ë Ï†ïÎãµ: 0Í∞ú\n",
                        "2025-11-26 21:43:51,069 - INFO -       - Ïû¨ÌòÑÏú®: 0.00%\n",
                        "\n",
                        "2025-11-26 21:43:51,071 - INFO - üìä ÌèâÍ∑† Ïû¨ÌòÑÏú® (Top 20): 2.39%\n",
                        "2025-11-26 21:43:51,072 - INFO - \n",
                        "üß™ ÌÖåÏä§Ìä∏ 2: Îã§ÏñëÌïú ÏãúÎìú Í≥° Ï∂îÏ≤ú Í≤∞Í≥º ÏÉòÌîåÎßÅ\n",
                        "\n",
                        "2025-11-26 21:43:51,226 - INFO - üéØ ÏãúÎìú Í≥° ID: 204517\n",
                        "2025-11-26 21:43:51,236 - INFO -    Ï∂îÏ≤ú Í≤∞Í≥º:\n",
                        "2025-11-26 21:43:51,237 - INFO -       1. Song ID 292233 (Ïú†ÏÇ¨ÎèÑ: 0.9953)\n",
                        "2025-11-26 21:43:51,237 - INFO -       2. Song ID 141877 (Ïú†ÏÇ¨ÎèÑ: 0.9942)\n",
                        "2025-11-26 21:43:51,238 - INFO -       3. Song ID 256887 (Ïú†ÏÇ¨ÎèÑ: 0.9933)\n",
                        "2025-11-26 21:43:51,238 - INFO -       4. Song ID 605982 (Ïú†ÏÇ¨ÎèÑ: 0.9932)\n",
                        "2025-11-26 21:43:51,239 - INFO -       5. Song ID 410788 (Ïú†ÏÇ¨ÎèÑ: 0.9932)\n",
                        "2025-11-26 21:43:51,239 - INFO - \n",
                        "2025-11-26 21:43:51,240 - INFO - üéØ ÏãúÎìú Í≥° ID: 583022\n",
                        "2025-11-26 21:43:51,249 - INFO -    Ï∂îÏ≤ú Í≤∞Í≥º:\n",
                        "2025-11-26 21:43:51,250 - INFO -       1. Song ID 360187 (Ïú†ÏÇ¨ÎèÑ: 0.9742)\n",
                        "2025-11-26 21:43:51,251 - INFO -       2. Song ID 285304 (Ïú†ÏÇ¨ÎèÑ: 0.9725)\n",
                        "2025-11-26 21:43:51,252 - INFO -       3. Song ID 39432 (Ïú†ÏÇ¨ÎèÑ: 0.9712)\n",
                        "2025-11-26 21:43:51,252 - INFO -       4. Song ID 685839 (Ïú†ÏÇ¨ÎèÑ: 0.9710)\n",
                        "2025-11-26 21:43:51,253 - INFO -       5. Song ID 316797 (Ïú†ÏÇ¨ÎèÑ: 0.9704)\n",
                        "2025-11-26 21:43:51,253 - INFO - \n",
                        "2025-11-26 21:43:51,254 - INFO - üéØ ÏãúÎìú Í≥° ID: 474445\n",
                        "2025-11-26 21:43:51,263 - INFO -    Ï∂îÏ≤ú Í≤∞Í≥º:\n",
                        "2025-11-26 21:43:51,265 - INFO -       1. Song ID 683008 (Ïú†ÏÇ¨ÎèÑ: 0.9529)\n",
                        "2025-11-26 21:43:51,266 - INFO -       2. Song ID 292781 (Ïú†ÏÇ¨ÎèÑ: 0.9521)\n",
                        "2025-11-26 21:43:51,267 - INFO -       3. Song ID 274481 (Ïú†ÏÇ¨ÎèÑ: 0.9489)\n",
                        "2025-11-26 21:43:51,267 - INFO -       4. Song ID 127223 (Ïú†ÏÇ¨ÎèÑ: 0.9465)\n",
                        "2025-11-26 21:43:51,268 - INFO -       5. Song ID 653202 (Ïú†ÏÇ¨ÎèÑ: 0.9444)\n",
                        "2025-11-26 21:43:51,268 - INFO - \n",
                        "2025-11-26 21:43:51,269 - INFO - \n",
                        "============================================================\n",
                        "2025-11-26 21:43:51,270 - INFO - ‚úÖ Step 7 ÏôÑÎ£å: ÌèâÍ∞Ä Î∞è Ï≤¥Í∞ê ÌÖåÏä§Ìä∏ ÏôÑÎ£å\n",
                        "2025-11-26 21:43:51,270 - INFO - ============================================================\n",
                        "2025-11-26 21:43:51,271 - INFO - \n",
                        "üéâ Stage 1 item2vec Î≤†Ïù¥Ïä§ÎùºÏù∏ Íµ¨Ï∂ïÏù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§!\n",
                        "2025-11-26 21:43:51,272 - INFO - \n",
                        "üí° Îã§Ïùå Îã®Í≥Ñ:\n",
                        "2025-11-26 21:43:51,273 - INFO -    - song_meta.jsonÏùÑ ÌôúÏö©Ìïú Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌÜµÌï©\n",
                        "2025-11-26 21:43:51,273 - INFO -    - ÌÉúÍ∑∏/ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Ï†úÎ™©ÏùÑ Ìï®Íªò ÌïôÏäµÌïòÎäî ÌôïÏû• Î≤ÑÏ†Ñ\n",
                        "2025-11-26 21:43:51,274 - INFO -    - Stage 2: Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Í∏∞Î∞ò Rule Refinement\n"
                    ]
                }
            ],
            "source": [
                "# Step 7 (ÏÑ†ÌÉù): Í∞ÑÎã®Ìïú ÌèâÍ∞Ä/Ï≤¥Í∞ê ÌÖåÏä§Ìä∏\n",
                "# item2vecÏù¥ ÏñºÎßàÎÇò Ìï©Î¶¨Ï†ÅÏù∏ Ï∂îÏ≤úÏùÑ ÌïòÎäîÏßÄ ÎåÄÎûµÏ†ÅÏúºÎ°ú ÌôïÏù∏Ìï©ÎãàÎã§\n",
                "\n",
                "logger.info(\"\\n\" + \"=\"*60)\n",
                "logger.info(\"Step 7 (ÏÑ†ÌÉù): ÌèâÍ∞Ä Î∞è Ï≤¥Í∞ê ÌÖåÏä§Ìä∏\")\n",
                "logger.info(\"=\"*60)\n",
                "\n",
                "# ========================================\n",
                "# ÌÖåÏä§Ìä∏ 1: Í∞ôÏùÄ ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ ÎÇ¥ Í≥° Ï∂îÏ≤ú Ïû¨ÌòÑÏú®\n",
                "# ========================================\n",
                "logger.info(\"\\nüß™ ÌÖåÏä§Ìä∏ 1: ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ ÎÇ¥ Í≥° Ï∂îÏ≤ú Ïû¨ÌòÑÏú® ÌôïÏù∏\")\n",
                "logger.info(\"   (Í∞ôÏùÄ ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏Ïóê ÏûàÎçò Í≥°Ïù¥ Ï∂îÏ≤ú Í≤∞Í≥ºÏóê ÏñºÎßàÎÇò Ìè¨Ìï®ÎêòÎäîÏßÄ ÌôïÏù∏)\\n\")\n",
                "\n",
                "# ÌÖåÏä§Ìä∏Ïö© ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ ÏÑ†ÌÉù (Í≥°Ïù¥ Ï∂©Î∂ÑÌûà ÎßéÏùÄ Í≤É)\n",
                "if 'train_data' in locals():\n",
                "    test_playlists = [p for p in train_data if len(p.get('songs', [])) >= 10][:5]\n",
                "else:\n",
                "    if 'logger' in locals(): logger.warning(\"‚ö†Ô∏è train_dataÍ∞Ä Î©îÎ™®Î¶¨Ïóê ÏóÜÏäµÎãàÎã§. Step 1ÏùÑ Ïã§ÌñâÌï¥Ï£ºÏÑ∏Ïöî. (ÌÖåÏä§Ìä∏ 1 Í±¥ÎÑàÎúÄ)\")\n",
                "    test_playlists = []\n",
                "\n",
                "recall_scores = []\n",
                "\n",
                "for idx, playlist in enumerate(test_playlists, 1):\n",
                "    songs = playlist['songs']\n",
                "    seed_song = songs[0]  # Ï≤´ Î≤àÏß∏ Í≥°ÏùÑ ÏãúÎìúÎ°ú ÏÇ¨Ïö©\n",
                "    ground_truth = set(songs[1:])  # ÎÇòÎ®∏ÏßÄ Í≥°Îì§Ïù¥ Ï†ïÎãµ ÌõÑÎ≥¥\n",
                "    \n",
                "    # Ï∂îÏ≤ú Í≤∞Í≥º\n",
                "    recommendations = get_similar_songs(w2v_model, seed_song, topn=20)\n",
                "    recommended_ids = set([song_id for song_id, _ in recommendations])\n",
                "    \n",
                "    # Ïû¨ÌòÑÏú® Í≥ÑÏÇ∞ (Ï∂îÏ≤úÎêú Í≥° Ï§ë Ïã§Ï†ú ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏Ïóê ÏûàÎçò Í≥°Ïùò ÎπÑÏú®)\n",
                "    hits = recommended_ids & ground_truth\n",
                "    recall = len(hits) / len(ground_truth) if len(ground_truth) > 0 else 0\n",
                "    recall_scores.append(recall)\n",
                "    \n",
                "    logger.info(f\"   ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ {idx}:\")\n",
                "    logger.info(f\"      - ÏãúÎìú Í≥°: {seed_song}\")\n",
                "    logger.info(f\"      - Ï†ïÎãµ Í≥° Ïàò: {len(ground_truth)}\")\n",
                "    logger.info(f\"      - Ï∂îÏ≤ú Í≥° Ï§ë Ï†ïÎãµ: {len(hits)}Í∞ú\")\n",
                "    logger.info(f\"      - Ïû¨ÌòÑÏú®: {recall:.2%}\\n\")\n",
                "\n",
                "avg_recall = np.mean(recall_scores)\n",
                "logger.info(f\"üìä ÌèâÍ∑† Ïû¨ÌòÑÏú® (Top 20): {avg_recall:.2%}\")\n",
                "\n",
                "# ========================================\n",
                "# ÌÖåÏä§Ìä∏ 2: Îã§ÏñëÌïú ÏãúÎìú Í≥°ÏúºÎ°ú Ï∂îÏ≤ú Í≤∞Í≥º ÌôïÏù∏\n",
                "# ========================================\n",
                "logger.info(\"\\nüß™ ÌÖåÏä§Ìä∏ 2: Îã§ÏñëÌïú ÏãúÎìú Í≥° Ï∂îÏ≤ú Í≤∞Í≥º ÏÉòÌîåÎßÅ\\n\")\n",
                "\n",
                "# ÎûúÎç§ÌïòÍ≤å Î™á Í∞ú Í≥° ÏÑ†ÌÉù\n",
                "np.random.seed(42)\n",
                "vocab_keys = list(w2v_model.wv.index_to_key)\n",
                "sample_seeds = np.random.choice(vocab_keys, size=min(3, len(vocab_keys)), replace=False)\n",
                "\n",
                "for seed in sample_seeds:\n",
                "    logger.info(f\"üéØ ÏãúÎìú Í≥° ID: {seed}\")\n",
                "    recommendations = get_similar_songs(w2v_model, int(seed), topn=5)\n",
                "    \n",
                "    if recommendations:\n",
                "        logger.info(\"   Ï∂îÏ≤ú Í≤∞Í≥º:\")\n",
                "        for rank, (song_id, similarity) in enumerate(recommendations, 1):\n",
                "            logger.info(f\"      {rank}. Song ID {song_id} (Ïú†ÏÇ¨ÎèÑ: {similarity:.4f})\")\n",
                "    logger.info(\"\")\n",
                "\n",
                "logger.info(\"\\n\" + \"=\"*60)\n",
                "logger.info(\"‚úÖ Step 7 ÏôÑÎ£å: ÌèâÍ∞Ä Î∞è Ï≤¥Í∞ê ÌÖåÏä§Ìä∏ ÏôÑÎ£å\")\n",
                "logger.info(\"=\"*60)\n",
                "logger.info(\"\\nüéâ Stage 1 item2vec Î≤†Ïù¥Ïä§ÎùºÏù∏ Íµ¨Ï∂ïÏù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§!\")\n",
                "logger.info(\"\\nüí° Îã§Ïùå Îã®Í≥Ñ:\")\n",
                "logger.info(\"   - song_meta.jsonÏùÑ ÌôúÏö©Ìïú Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌÜµÌï©\")\n",
                "logger.info(\"   - ÌÉúÍ∑∏/ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Ï†úÎ™©ÏùÑ Ìï®Íªò ÌïôÏäµÌïòÎäî ÌôïÏû• Î≤ÑÏ†Ñ\")\n",
                "logger.info(\"   - Stage 2: Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Í∏∞Î∞ò Rule Refinement\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "Step 7.5: Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖã Recall@20 ÌèâÍ∞Ä\n",
                        "============================================================\n",
                        "üîç ÌèâÍ∞Ä ÏßÑÌñâ Ï§ë... (ÏÉòÌîå 1000Í∞ú)\n",
                        "\n",
                        "üìä ÏµúÏ¢Ö ÌèâÍ∞Ä Í≤∞Í≥º:\n",
                        "   ‚ñ∫ Average Recall@20 : 0.0253 (2.53%)\n",
                        "   ‚ñ∫ (Ï∞∏Í≥†) Î™®Îç∏ ÎØ∏Ìè¨Ìï® ÏãúÎìú Í≥° : 49Í∞ú (4.9%)\n",
                        "============================================================\n"
                    ]
                }
            ],
            "source": [
                "# Step 7.5: Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖã Recall@20 ÌèâÍ∞Ä (Simple Version)\n",
                "# Î∂àÌïÑÏöîÌïú Î°úÍ∑∏Î•º Ï†úÍ±∞ÌïòÍ≥† ÌïµÏã¨ ÏßÄÌëú(Recall@20)Îßå Ï∂úÎ†•Ìï©ÎãàÎã§.\n",
                "\n",
                "logger.info(\"\\n\" + \"=\"*60)\n",
                "logger.info(\"Step 7.5: Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖã Recall@20 ÌèâÍ∞Ä\")\n",
                "logger.info(\"=\"*60)\n",
                "\n",
                "if 'train_data' in locals():\n",
                "    # 1. ÌèâÍ∞Ä ÎåÄÏÉÅ ÏÑ†Ï†ï (Í≥° 10Í∞ú Ïù¥ÏÉÅ)\n",
                "    valid_playlists = [p for p in train_data if len(p.get('songs', [])) >= 10]\n",
                "    \n",
                "    # 2. ÏÉòÌîåÎßÅ (1,000Í∞ú)\n",
                "    import random\n",
                "    random.seed(42)\n",
                "    sample_size = min(1000, len(valid_playlists))\n",
                "    eval_playlists = random.sample(valid_playlists, sample_size)\n",
                "    \n",
                "    logger.info(f\"üîç ÌèâÍ∞Ä ÏßÑÌñâ Ï§ë... (ÏÉòÌîå {sample_size}Í∞ú)\")\n",
                "    \n",
                "    recall_scores = []\n",
                "    missing_seed_count = 0\n",
                "    \n",
                "    # 3. ÌèâÍ∞Ä Î£®ÌîÑ\n",
                "    for playlist in eval_playlists:\n",
                "        songs = playlist['songs']\n",
                "        seed_song = songs[0]\n",
                "        ground_truth = set(songs[1:])\n",
                "        \n",
                "        # ÏãúÎìú Í≥°Ïù¥ Î™®Îç∏Ïóê ÏûàÎäîÏßÄ ÌôïÏù∏ (Î°úÍ∑∏ ÏóÜÏù¥ Ï°∞Ïö©Ìûà Ï≤òÎ¶¨)\n",
                "        if str(seed_song) not in w2v_model.wv:\n",
                "            missing_seed_count += 1\n",
                "            recall_scores.append(0) # Ï∂îÏ≤ú Î∂àÍ∞ÄÌïòÎØÄÎ°ú Recall 0\n",
                "            continue\n",
                "            \n",
                "        # Ï∂îÏ≤ú (Í≤ΩÍ≥† Î°úÍ∑∏Î•º ÌîºÌïòÍ∏∞ ÏúÑÌï¥ ÏßÅÏ†ë Î™®Îç∏ Ìò∏Ï∂ú)\n",
                "        try:\n",
                "            similar_items = w2v_model.wv.most_similar(str(seed_song), topn=20)\n",
                "            recommended_ids = set([int(sid) for sid, _ in similar_items])\n",
                "            \n",
                "            # Recall Í≥ÑÏÇ∞\n",
                "            hits = recommended_ids & ground_truth\n",
                "            recall = len(hits) / len(ground_truth) if len(ground_truth) > 0 else 0\n",
                "            recall_scores.append(recall)\n",
                "            \n",
                "        except KeyError:\n",
                "            missing_seed_count += 1\n",
                "            recall_scores.append(0)\n",
                "            \n",
                "    # 4. Í≤∞Í≥º Ï∂úÎ†•\n",
                "    avg_recall = np.mean(recall_scores)\n",
                "    \n",
                "    logger.info(f\"\\nüìä ÏµúÏ¢Ö ÌèâÍ∞Ä Í≤∞Í≥º:\")\n",
                "    logger.info(f\"   ‚ñ∫ Average Recall@20 : {avg_recall:.4f} ({avg_recall*100:.2f}%)\")\n",
                "    logger.info(f\"   ‚ñ∫ (Ï∞∏Í≥†) Î™®Îç∏ ÎØ∏Ìè¨Ìï® ÏãúÎìú Í≥° : {missing_seed_count}Í∞ú ({missing_seed_count/sample_size*100:.1f}%)\")\n",
                "    logger.info(\"=\"*60)\n",
                "\n",
                "else:\n",
                "    logger.warning(\"‚ö†Ô∏è train_dataÍ∞Ä Î©îÎ™®Î¶¨Ïóê ÏóÜÏäµÎãàÎã§.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-11-26 21:44:32,810 - INFO - üìÇ song_meta.json Î°úÎìú Ï§ë...\n",
                        "2025-11-26 21:44:40,077 - INFO - ‚úÖ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Î°úÎìú ÏôÑÎ£å: 707,989Í≥°\n",
                        "2025-11-26 21:44:40,078 - INFO - \n",
                        "üéØ ÏãúÎìú Í≥° Ï†ïÎ≥¥: [Hey Little Girl] - The Sol (ID: 525514)\n",
                        "2025-11-26 21:44:40,078 - INFO -    Ï∂îÏ≤ú Í≤∞Í≥º (Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ìè¨Ìï®):\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Song ID</th>\n",
                            "      <th>Ïú†ÏÇ¨ÎèÑ</th>\n",
                            "      <th>Í≥°Î™Ö</th>\n",
                            "      <th>ÏïÑÌã∞Ïä§Ìä∏</th>\n",
                            "      <th>Ïû•Î•¥</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>695342</td>\n",
                            "      <td>0.984490</td>\n",
                            "      <td>I Want Crazy (Encore)</td>\n",
                            "      <td>Hunter Hayes</td>\n",
                            "      <td>[GN1400]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>658448</td>\n",
                            "      <td>0.978754</td>\n",
                            "      <td>Moving</td>\n",
                            "      <td>Travis</td>\n",
                            "      <td>[GN1000]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>423887</td>\n",
                            "      <td>0.978368</td>\n",
                            "      <td>Nothing Stays The Same</td>\n",
                            "      <td>Luke Sital-Singh</td>\n",
                            "      <td>[GN1400]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>15811</td>\n",
                            "      <td>0.975316</td>\n",
                            "      <td>I Wish I Could Break Your Heart</td>\n",
                            "      <td>Cassadee Pope</td>\n",
                            "      <td>[GN1400]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>552048</td>\n",
                            "      <td>0.975251</td>\n",
                            "      <td>We Don`t Have To Take Our Clothes Off</td>\n",
                            "      <td>Ella Eyre</td>\n",
                            "      <td>[GN1300]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>108392</td>\n",
                            "      <td>0.973768</td>\n",
                            "      <td>Architect</td>\n",
                            "      <td>Frightened Rabbit, Manchester Orchestra</td>\n",
                            "      <td>[GN0900, GN1000]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>650362</td>\n",
                            "      <td>0.973646</td>\n",
                            "      <td>Sad, Sad World</td>\n",
                            "      <td>Jamie Cullum</td>\n",
                            "      <td>[GN1700]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>487399</td>\n",
                            "      <td>0.973358</td>\n",
                            "      <td>Under (Pop Ver.)</td>\n",
                            "      <td>Alex Hepburn</td>\n",
                            "      <td>[GN0900]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>200922</td>\n",
                            "      <td>0.973239</td>\n",
                            "      <td>Today&amp;#39;s Not Yesterday</td>\n",
                            "      <td>Shane Filan</td>\n",
                            "      <td>[GN0900]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>343991</td>\n",
                            "      <td>0.973036</td>\n",
                            "      <td>Dancehall</td>\n",
                            "      <td>Tribes</td>\n",
                            "      <td>[GN1000]</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   Song ID       Ïú†ÏÇ¨ÎèÑ                                     Í≥°Î™Ö  \\\n",
                            "0   695342  0.984490                  I Want Crazy (Encore)   \n",
                            "1   658448  0.978754                                 Moving   \n",
                            "2   423887  0.978368                 Nothing Stays The Same   \n",
                            "3    15811  0.975316        I Wish I Could Break Your Heart   \n",
                            "4   552048  0.975251  We Don`t Have To Take Our Clothes Off   \n",
                            "5   108392  0.973768                              Architect   \n",
                            "6   650362  0.973646                         Sad, Sad World   \n",
                            "7   487399  0.973358                       Under (Pop Ver.)   \n",
                            "8   200922  0.973239              Today&#39;s Not Yesterday   \n",
                            "9   343991  0.973036                              Dancehall   \n",
                            "\n",
                            "                                      ÏïÑÌã∞Ïä§Ìä∏                Ïû•Î•¥  \n",
                            "0                             Hunter Hayes          [GN1400]  \n",
                            "1                                   Travis          [GN1000]  \n",
                            "2                         Luke Sital-Singh          [GN1400]  \n",
                            "3                           Cassadee Pope           [GN1400]  \n",
                            "4                                Ella Eyre          [GN1300]  \n",
                            "5  Frightened Rabbit, Manchester Orchestra  [GN0900, GN1000]  \n",
                            "6                             Jamie Cullum          [GN1700]  \n",
                            "7                             Alex Hepburn          [GN0900]  \n",
                            "8                              Shane Filan          [GN0900]  \n",
                            "9                                   Tribes          [GN1000]  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Step 8 (Ï∂îÍ∞Ä): Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ìè¨Ìï® Ï∂îÏ≤ú Í≤∞Í≥º ÌôïÏù∏\n",
                "# song_meta.jsonÏùÑ Î°úÎìúÌïòÏó¨ Í≥°Î™Ö, ÏïÑÌã∞Ïä§Ìä∏ Ï†ïÎ≥¥Î•º Ìï®Íªò Î≥¥Ïó¨Ï§çÎãàÎã§\n",
                "\n",
                "import os\n",
                "import json\n",
                "import pandas as pd\n",
                "from IPython.display import display\n",
                "\n",
                "# 1. song_meta.json Î°úÎìú\n",
                "SONG_META_JSON_PATH = os.path.join(DATA_ROOT, \"song_meta.json\")\n",
                "\n",
                "if os.path.exists(SONG_META_JSON_PATH):\n",
                "    logger.info(\"üìÇ song_meta.json Î°úÎìú Ï§ë...\")\n",
                "    with open(SONG_META_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
                "        song_meta = json.load(f)\n",
                "    \n",
                "    # Í≤ÄÏÉâ ÏÜçÎèÑÎ•º ÏúÑÌï¥ ÎîïÏÖîÎÑàÎ¶¨Î°ú Î≥ÄÌôò (List -> Dict)\n",
                "    # key: song_id, value: song_info\n",
                "    song_meta_dict = {song['id']: song for song in song_meta}\n",
                "    logger.info(f\"‚úÖ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Î°úÎìú ÏôÑÎ£å: {len(song_meta_dict):,}Í≥°\")\n",
                "\n",
                "    # 2. Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ìè¨Ìï® Ï∂îÏ≤ú Ìï®Ïàò Ï†ïÏùò\n",
                "    def show_recommendations_with_meta(seed_id, topn=10):\n",
                "        # Ïú†ÏÇ¨ Í≥° Ï∂îÏ≤ú Î∞õÍ∏∞\n",
                "        recs = get_similar_songs(w2v_model, seed_id, topn=topn)\n",
                "        \n",
                "        rows = []\n",
                "        for sid, score in recs:\n",
                "            # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï°∞Ìöå\n",
                "            meta = song_meta_dict.get(sid)\n",
                "            \n",
                "            if meta:\n",
                "                song_name = meta.get(\"song_name\", \"Unknown\")\n",
                "                # ÏïÑÌã∞Ïä§Ìä∏Îäî Î¶¨Ïä§Ìä∏ ÌòïÌÉú(artist_name_basket)Î°ú Ï†úÍ≥µÎê®\n",
                "                artists = meta.get(\"artist_name_basket\", [])\n",
                "                artist_str = \", \".join(artists) if artists else \"Unknown\"\n",
                "                genres = meta.get(\"song_gn_gnr_basket\", [])\n",
                "            else:\n",
                "                song_name = f\"Unknown (ID: {sid})\"\n",
                "                artist_str = \"-\"\n",
                "                genres = []\n",
                "\n",
                "            rows.append({\n",
                "                \"Song ID\": sid,\n",
                "                \"Ïú†ÏÇ¨ÎèÑ\": score,\n",
                "                \"Í≥°Î™Ö\": song_name,\n",
                "                \"ÏïÑÌã∞Ïä§Ìä∏\": artist_str,\n",
                "                \"Ïû•Î•¥\": genres\n",
                "            })\n",
                "            \n",
                "        return pd.DataFrame(rows)\n",
                "\n",
                "    # 3. Ìï®Ïàò Ïã§Ìñâ Î∞è Í≤∞Í≥º Ï∂úÎ†•\n",
                "    # ÏòàÏãú: ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Ïóê ÏûàÎäî Ï≤´ Î≤àÏß∏ Í≥°ÏúºÎ°ú ÌÖåÏä§Ìä∏\n",
                "    # (Step 6ÏóêÏÑú ÏÇ¨Ïö©ÌñàÎçò seed_song_id Ïû¨ÏÇ¨Ïö©)\n",
                "    if 'seed_song_id' not in locals():\n",
                "        seed_song_id = train_data[0]['songs'][0]\n",
                "        \n",
                "    # ÏãúÎìú Í≥° Ï†ïÎ≥¥ ÌôïÏù∏\n",
                "    seed_meta = song_meta_dict.get(seed_song_id)\n",
                "    if seed_meta:\n",
                "        seed_name = seed_meta.get(\"song_name\", \"Unknown\")\n",
                "        seed_artists = seed_meta.get(\"artist_name_basket\", [])\n",
                "        seed_artist_str = \", \".join(seed_artists) if seed_artists else \"Unknown\"\n",
                "    else:\n",
                "        seed_name = \"Unknown\"\n",
                "        seed_artist_str = \"Unknown\"\n",
                "\n",
                "    logger.info(f\"\\nüéØ ÏãúÎìú Í≥° Ï†ïÎ≥¥: [{seed_name}] - {seed_artist_str} (ID: {seed_song_id})\")\n",
                "    logger.info(\"   Ï∂îÏ≤ú Í≤∞Í≥º (Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ìè¨Ìï®):\")\n",
                "    \n",
                "    # DataFrame ÏÉùÏÑ± Î∞è Ï∂úÎ†•\n",
                "    rec_df = show_recommendations_with_meta(seed_song_id)\n",
                "    display(rec_df)\n",
                "\n",
                "else:\n",
                "    logger.warning(f\"‚ö†Ô∏è song_meta.json ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {SONG_META_JSON_PATH}\")\n",
                "    logger.warning(\"DATA_ROOT Í≤ΩÎ°úÎ•º ÌôïÏù∏ÌïòÍ±∞ÎÇò ÌååÏùºÏùÑ ÏóÖÎ°úÎìúÌï¥Ï£ºÏÑ∏Ïöî.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-11-26 21:48:54,271 - INFO - üìä Í≥° Îì±Ïû• ÌöüÏàò Î∂ÑÌè¨ Î∂ÑÏÑù Ï§ë... (ÏãúÍ∞ÑÏù¥ Ï°∞Í∏à Í±∏Î¶¥ Ïàò ÏûàÏäµÎãàÎã§)\n",
                        "2025-11-26 21:48:55,706 - INFO - \n",
                        "üìà Í≥° Îì±Ïû• ÎπàÎèÑ Î∂ÑÏÑù Í≤∞Í≥º\n",
                        "==================================================\n",
                        "  Ï¥ù Í≥†Ïú† Í≥° Ïàò (Unique Songs): 615,142Í∞ú\n",
                        "==================================================\n",
                        "  [ÏÑ∏Î∂Ä Î∂ÑÌè¨]\n",
                        "  - 1Î≤àÎßå Îì±Ïû•Ìïú Í≥° : 299,028Í∞ú (48.6%)\n",
                        "  - 2Î≤àÎßå Îì±Ïû•Ìïú Í≥° :  94,458Í∞ú (15.4%)\n",
                        "--------------------------------------------------\n",
                        "  ‚ñ∫ 3Î≤à ÎØ∏Îßå (Ï†úÏô∏Îê®) : 393,486Í∞ú (64.0%)\n",
                        "  ‚ñ∫ 3Î≤à Ïù¥ÏÉÅ (ÌïôÏäµÎê®) : 221,656Í∞ú (36.0%)\n",
                        "==================================================\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚ö†Ô∏è [Ìï¥ÏÑù] Ï†ÑÏ≤¥ Í≥°Ïùò Ï†àÎ∞ò Ïù¥ÏÉÅÏù¥ ÌïôÏäµÏóêÏÑú Ï†úÏô∏ÎêòÍ≥† ÏûàÏäµÎãàÎã§.\n",
                        "   -> min_count=2Î°ú ÎÇÆÏ∂îÎäî Í≤ÉÏùÑ Í≥†Î†§Ìï¥Î≥¥ÏÑ∏Ïöî. (Recall ÏÉÅÏäπ Í∞ÄÎä•ÏÑ± ÏûàÏùå)\n"
                    ]
                }
            ],
            "source": [
                "from collections import Counter\n",
                "\n",
                "# 1. Ï†ÑÏ≤¥ Í≥° Îì±Ïû• ÌöüÏàò Ïπ¥Ïö¥Ìä∏\n",
                "if 'logger' in locals():\n",
                "    logger.info(\"üìä Í≥° Îì±Ïû• ÌöüÏàò Î∂ÑÌè¨ Î∂ÑÏÑù Ï§ë... (ÏãúÍ∞ÑÏù¥ Ï°∞Í∏à Í±∏Î¶¥ Ïàò ÏûàÏäµÎãàÎã§)\")\n",
                "else:\n",
                "    print(\"üìä Í≥° Îì±Ïû• ÌöüÏàò Î∂ÑÌè¨ Î∂ÑÏÑù Ï§ë... (ÏãúÍ∞ÑÏù¥ Ï°∞Í∏à Í±∏Î¶¥ Ïàò ÏûàÏäµÎãàÎã§)\")\n",
                "\n",
                "# Î™®Îì† ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏Ïùò Í≥°ÏùÑ ÌïòÎÇòÏùò Î¶¨Ïä§Ìä∏Î°ú Î™®ÏúºÍ∏∞ (Î©îÎ™®Î¶¨ Ï£ºÏùò: ÎÑàÎ¨¥ ÌÅ¨Î©¥ generator Î∞©Ïãù ÏÇ¨Ïö© Í∂åÏû•)\n",
                "# Ïó¨Í∏∞ÏÑúÎäî Îã®ÏàúÌïòÍ≤å Î£®ÌîÑ ÎèåÎ©¥ÏÑú Ïπ¥Ïö¥ÌåÖ\n",
                "song_counter = Counter()\n",
                "for playlist in train_data:\n",
                "    song_counter.update(playlist['songs'])\n",
                "\n",
                "# 2. ÌÜµÍ≥Ñ Í≥ÑÏÇ∞\n",
                "total_unique_songs = len(song_counter)\n",
                "count_1 = sum(1 for c in song_counter.values() if c == 1)\n",
                "count_2 = sum(1 for c in song_counter.values() if c == 2)\n",
                "count_under_3 = count_1 + count_2\n",
                "count_3_plus = total_unique_songs - count_under_3\n",
                "\n",
                "# 3. Í≤∞Í≥º Ï∂úÎ†•\n",
                "msg = f\"\"\"\n",
                "üìà Í≥° Îì±Ïû• ÎπàÎèÑ Î∂ÑÏÑù Í≤∞Í≥º\n",
                "==================================================\n",
                "  Ï¥ù Í≥†Ïú† Í≥° Ïàò (Unique Songs): {total_unique_songs:,}Í∞ú\n",
                "==================================================\n",
                "  [ÏÑ∏Î∂Ä Î∂ÑÌè¨]\n",
                "  - 1Î≤àÎßå Îì±Ïû•Ìïú Í≥° : {count_1:7,}Í∞ú ({count_1/total_unique_songs*100:.1f}%)\n",
                "  - 2Î≤àÎßå Îì±Ïû•Ìïú Í≥° : {count_2:7,}Í∞ú ({count_2/total_unique_songs*100:.1f}%)\n",
                "--------------------------------------------------\n",
                "  ‚ñ∫ 3Î≤à ÎØ∏Îßå (Ï†úÏô∏Îê®) : {count_under_3:7,}Í∞ú ({count_under_3/total_unique_songs*100:.1f}%)\n",
                "  ‚ñ∫ 3Î≤à Ïù¥ÏÉÅ (ÌïôÏäµÎê®) : {count_3_plus:7,}Í∞ú ({count_3_plus/total_unique_songs*100:.1f}%)\n",
                "==================================================\n",
                "\"\"\"\n",
                "\n",
                "if 'logger' in locals():\n",
                "    logger.info(msg)\n",
                "else:\n",
                "    print(msg)\n",
                "\n",
                "# 4. Í∞ÑÎã®Ìïú Ìï¥ÏÑù\n",
                "if count_under_3 / total_unique_songs > 0.5:\n",
                "    print(\"‚ö†Ô∏è [Ìï¥ÏÑù] Ï†ÑÏ≤¥ Í≥°Ïùò Ï†àÎ∞ò Ïù¥ÏÉÅÏù¥ ÌïôÏäµÏóêÏÑú Ï†úÏô∏ÎêòÍ≥† ÏûàÏäµÎãàÎã§.\")\n",
                "    print(\"   -> min_count=2Î°ú ÎÇÆÏ∂îÎäî Í≤ÉÏùÑ Í≥†Î†§Ìï¥Î≥¥ÏÑ∏Ïöî. (Recall ÏÉÅÏäπ Í∞ÄÎä•ÏÑ± ÏûàÏùå)\")\n",
                "else:\n",
                "    print(\"‚úÖ [Ìï¥ÏÑù] Ï†úÏô∏ÎêòÎäî Í≥° ÎπÑÏú®Ïù¥ ÏñëÌò∏Ìï©ÎãàÎã§. min_count=3 Ïú†ÏßÄÎèÑ Í¥úÏ∞ÆÏäµÎãàÎã§.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "üîç Î™®Îç∏ Î°úÎìú Î∞è Ïª§Î≤ÑÎ¶¨ÏßÄ Î∂ÑÏÑù ÏãúÏûë...\n",
                        "   - Ï†ÑÏ≤¥ Í≥†Ïú† Í≥° Ïàò: 615,142Í∞ú\n",
                        "loading Word2Vec object from ./models\\models\\v1_item2vec\\item2vec.model\n",
                        "loading wv recursively from ./models\\models\\v1_item2vec\\item2vec.model.wv.* with mmap=None\n",
                        "loading vectors from ./models\\models\\v1_item2vec\\item2vec.model.wv.vectors.npy with mmap=None\n",
                        "loading syn1neg from ./models\\models\\v1_item2vec\\item2vec.model.syn1neg.npy with mmap=None\n",
                        "setting ignored attribute cum_table to None\n",
                        "Word2Vec lifecycle event {'fname': './models\\\\models\\\\v1_item2vec\\\\item2vec.model', 'datetime': '2025-11-27T17:47:31.285888', 'gensim': '4.4.0', 'python': '3.13.7 | packaged by Anaconda, Inc. | (main, Sep  9 2025, 19:54:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'}\n",
                        "   - [min=3] Vocab: 221,653Í∞ú (Ïª§Î≤ÑÎ¶¨ÏßÄ: 36.03%)\n",
                        "loading Word2Vec object from ./models\\models\\v2_item2vec.model\n",
                        "loading wv recursively from ./models\\models\\v2_item2vec.model.wv.* with mmap=None\n",
                        "loading vectors from ./models\\models\\v2_item2vec.model.wv.vectors.npy with mmap=None\n",
                        "loading syn1neg from ./models\\models\\v2_item2vec.model.syn1neg.npy with mmap=None\n",
                        "setting ignored attribute cum_table to None\n",
                        "Word2Vec lifecycle event {'fname': './models\\\\models\\\\v2_item2vec.model', 'datetime': '2025-11-27T17:47:33.769068', 'gensim': '4.4.0', 'python': '3.13.7 | packaged by Anaconda, Inc. | (main, Sep  9 2025, 19:54:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'}\n",
                        "   - [min=2] Vocab: 316,109Í∞ú (Ïª§Î≤ÑÎ¶¨ÏßÄ: 51.39%)\n"
                    ]
                }
            ],
            "source": [
                "# [Cell A] Î™®Îç∏ Î°úÎìú Î∞è Vocab Ïª§Î≤ÑÎ¶¨ÏßÄ Î∂ÑÏÑù\n",
                "\n",
                "import os\n",
                "from gensim.models import Word2Vec\n",
                "\n",
                "# Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
                "MODEL_DIR = \"./models\"\n",
                "PATH_MIN3 = os.path.join(MODEL_DIR, \"models\", \"v1_item2vec\", \"item2vec.model\")      # Í∏∞Ï°¥ (min=3)\n",
                "PATH_MIN2 = os.path.join(MODEL_DIR, \"models\", \"v2_item2vec.model\") # Ïã†Í∑ú (min=2)\n",
                "\n",
                "logger.info(\"üîç Î™®Îç∏ Î°úÎìú Î∞è Ïª§Î≤ÑÎ¶¨ÏßÄ Î∂ÑÏÑù ÏãúÏûë...\")\n",
                "\n",
                "# 1. Ï†ÑÏ≤¥ Í≥†Ïú† Í≥° Ïàò Í≥ÑÏÇ∞ (train_data Í∏∞Ï§Ä)\n",
                "if 'train_data' in locals():\n",
                "    all_songs = set()\n",
                "    for p in train_data:\n",
                "        all_songs.update(p['songs'])\n",
                "    total_unique_songs = len(all_songs)\n",
                "else:\n",
                "    logger.warning(\"‚ö†Ô∏è train_dataÍ∞Ä ÏóÜÏäµÎãàÎã§. Step 1ÏùÑ Î®ºÏ†Ä Ïã§ÌñâÌï¥Ï£ºÏÑ∏Ïöî.\")\n",
                "    total_unique_songs = 615142 # ÎåÄÎûµÏ†ÅÏù∏ ÏàòÏπò (Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Í∏∞Ï§Ä)\n",
                "\n",
                "logger.info(f\"   - Ï†ÑÏ≤¥ Í≥†Ïú† Í≥° Ïàò: {total_unique_songs:,}Í∞ú\")\n",
                "\n",
                "# 2. Î™®Îç∏ Î°úÎìú Î∞è Vocab ÌôïÏù∏\n",
                "models = {}\n",
                "\n",
                "# (1) min_count=3 Î™®Îç∏\n",
                "if os.path.exists(PATH_MIN3):\n",
                "    model_min3 = Word2Vec.load(PATH_MIN3)\n",
                "    vocab_min3 = len(model_min3.wv)\n",
                "    models['min3'] = model_min3\n",
                "    logger.info(f\"   - [min=3] Vocab: {vocab_min3:,}Í∞ú (Ïª§Î≤ÑÎ¶¨ÏßÄ: {vocab_min3/total_unique_songs*100:.2f}%)\")\n",
                "else:\n",
                "    logger.warning(f\"   - [min=3] Î™®Îç∏ ÌååÏùº ÏóÜÏùå: {PATH_MIN3}\")\n",
                "\n",
                "# (2) min_count=2 Î™®Îç∏\n",
                "if os.path.exists(PATH_MIN2):\n",
                "    model_min2 = Word2Vec.load(PATH_MIN2)\n",
                "    vocab_min2 = len(model_min2.wv)\n",
                "    models['min2'] = model_min2\n",
                "    logger.info(f\"   - [min=2] Vocab: {vocab_min2:,}Í∞ú (Ïª§Î≤ÑÎ¶¨ÏßÄ: {vocab_min2/total_unique_songs*100:.2f}%)\")\n",
                "else:\n",
                "    logger.warning(f\"   - [min=2] Î™®Îç∏ ÌååÏùº ÏóÜÏùå: {PATH_MIN2} (ÌïôÏäµ ÌïÑÏöî)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Cell B] Í≥µÌÜµ ÌèâÍ∞Ä Ìï®Ïàò Ï†ïÏùò\n",
                "\n",
                "def evaluate_item2vec_recall(model, playlists, k=20):\n",
                "    \"\"\"\n",
                "    Ï£ºÏñ¥ÏßÑ Î™®Îç∏Í≥º ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ ÏÑ∏Ìä∏Ïóê ÎåÄÌï¥ Recall@K ÏÑ±Îä•ÏùÑ ÌèâÍ∞ÄÌï©ÎãàÎã§.\n",
                "    \"\"\"\n",
                "    recall_scores = []\n",
                "    missing_seed_count = 0\n",
                "    total_samples = 0\n",
                "    \n",
                "    for playlist in playlists:\n",
                "        songs = playlist.get('songs', [])\n",
                "        if len(songs) < 2: # ÏµúÏÜå 2Í≥° Ïù¥ÏÉÅÏù¥Ïñ¥Ïïº ÌèâÍ∞Ä Í∞ÄÎä• (Seed + Ground Truth)\n",
                "            continue\n",
                "            \n",
                "        total_samples += 1\n",
                "        seed_song = str(songs[0])\n",
                "        ground_truth = set(songs[1:])\n",
                "        \n",
                "        # ÏãúÎìú Í≥°Ïù¥ Î™®Îç∏Ïóê ÏóÜÎäî Í≤ΩÏö∞ (Cold Start)\n",
                "        if seed_song not in model.wv:\n",
                "            missing_seed_count += 1\n",
                "            recall_scores.append(0.0)\n",
                "            continue\n",
                "            \n",
                "        try:\n",
                "            # Ï∂îÏ≤ú ÏàòÌñâ\n",
                "            similar_items = model.wv.most_similar(seed_song, topn=k)\n",
                "            recommended_ids = set([int(sid) for sid, _ in similar_items])\n",
                "            \n",
                "            # Recall Í≥ÑÏÇ∞\n",
                "            hits = recommended_ids & ground_truth\n",
                "            recall = len(hits) / len(ground_truth) if len(ground_truth) > 0 else 0\n",
                "            recall_scores.append(recall)\n",
                "            \n",
                "        except Exception:\n",
                "            missing_seed_count += 1\n",
                "            recall_scores.append(0.0)\n",
                "            \n",
                "    # ÌÜµÍ≥Ñ Í≥ÑÏÇ∞\n",
                "    if not recall_scores:\n",
                "        return {\n",
                "            \"recall_mean\": 0.0, \"recall_median\": 0.0, \"recall_std\": 0.0,\n",
                "            \"cold_start_rate\": 0.0, \"num_samples\": 0\n",
                "        }\n",
                "        \n",
                "    return {\n",
                "        \"recall_mean\": np.mean(recall_scores),\n",
                "        \"recall_median\": np.median(recall_scores),\n",
                "        \"recall_std\": np.std(recall_scores),\n",
                "        \"cold_start_rate\": missing_seed_count / total_samples * 100 if total_samples > 0 else 0,\n",
                "        \"num_samples\": total_samples\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "üìä ÏÑ±Îä• ÎπÑÍµê ÏãúÏûë (ÏÉòÌîå 1000Í∞ú)...\n",
                        "============================================================\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[min3 Î™®Îç∏ Í≤∞Í≥º]\n",
                        "   ‚ñ∫ Recall@20 Mean : 0.0249 (2.49%)\n",
                        "   ‚ñ∫ Recall@20 Median: 0.0000\n",
                        "   ‚ñ∫ Cold Start Rate : 8.8%\n",
                        "----------------------------------------\n",
                        "[min2 Î™®Îç∏ Í≤∞Í≥º]\n",
                        "   ‚ñ∫ Recall@20 Mean : 0.0253 (2.53%)\n",
                        "   ‚ñ∫ Recall@20 Median: 0.0000\n",
                        "   ‚ñ∫ Cold Start Rate : 4.9%\n",
                        "----------------------------------------\n",
                        "üìà [ÏµúÏ¢Ö ÎπÑÍµê]\n",
                        "   min=2 Î™®Îç∏Ïù¥ min=3 ÎåÄÎπÑ RecallÏù¥ +1.6% Î≥ÄÌôîÌñàÏäµÎãàÎã§. (+0.0004)\n",
                        "   ‚úÖ min=2 Î™®Îç∏ Ï±ÑÌÉù Í∂åÏû• (ÏÑ±Îä• Ïú†ÏßÄ/Ìñ•ÏÉÅ + Ïª§Î≤ÑÎ¶¨ÏßÄ Ï¶ùÍ∞Ä)\n"
                    ]
                }
            ],
            "source": [
                "# [Cell C] ÏÑ±Îä• ÎπÑÍµê Ïã§Ìñâ (min=3 vs min=2)\n",
                "\n",
                "if 'train_data' in locals() and len(models) > 0:\n",
                "    # 1. ÌèâÍ∞Ä ÏÉòÌîåÎßÅ (Í≥µÏ†ï ÎπÑÍµêÎ•º ÏúÑÌï¥ ÎèôÏùº ÏÉòÌîå ÏÇ¨Ïö©)\n",
                "    import random\n",
                "    random.seed(42)\n",
                "    \n",
                "    # Í≥° 10Í∞ú Ïù¥ÏÉÅÏù∏ ÌîåÎ†àÏù¥Î¶¨Ïä§Ìä∏ Ï§ë 1,000Í∞ú Ï∂îÏ∂ú\n",
                "    valid_playlists = [p for p in train_data if len(p.get('songs', [])) >= 10]\n",
                "    sample_size = min(1000, len(valid_playlists))\n",
                "    playlists_eval = random.sample(valid_playlists, sample_size)\n",
                "    \n",
                "    logger.info(f\"üìä ÏÑ±Îä• ÎπÑÍµê ÏãúÏûë (ÏÉòÌîå {sample_size}Í∞ú)...\")\n",
                "    logger.info(\"=\"*60)\n",
                "    \n",
                "    # 2. Í∞Å Î™®Îç∏ ÌèâÍ∞Ä\n",
                "    results = {}\n",
                "    for name, model in models.items():\n",
                "        res = evaluate_item2vec_recall(model, playlists_eval, k=20)\n",
                "        results[name] = res\n",
                "        \n",
                "        logger.info(f\"[{name} Î™®Îç∏ Í≤∞Í≥º]\")\n",
                "        logger.info(f\"   ‚ñ∫ Recall@20 Mean : {res['recall_mean']:.4f} ({res['recall_mean']*100:.2f}%)\")\n",
                "        logger.info(f\"   ‚ñ∫ Recall@20 Median: {res['recall_median']:.4f}\")\n",
                "        logger.info(f\"   ‚ñ∫ Cold Start Rate : {res['cold_start_rate']:.1f}%\")\n",
                "        logger.info(\"-\"*40)\n",
                "        \n",
                "    # 3. ÏµúÏ¢Ö ÎπÑÍµê ÏöîÏïΩ\n",
                "    if 'min3' in results and 'min2' in results:\n",
                "        r3 = results['min3']['recall_mean']\n",
                "        r2 = results['min2']['recall_mean']\n",
                "        diff = r2 - r3\n",
                "        improvement = (diff / r3 * 100) if r3 > 0 else 0\n",
                "        \n",
                "        logger.info(\"üìà [ÏµúÏ¢Ö ÎπÑÍµê]\")\n",
                "        logger.info(f\"   min=2 Î™®Îç∏Ïù¥ min=3 ÎåÄÎπÑ RecallÏù¥ {improvement:+.1f}% Î≥ÄÌôîÌñàÏäµÎãàÎã§. ({diff:+.4f})\")\n",
                "        \n",
                "        if r2 >= r3:\n",
                "            logger.info(\"   ‚úÖ min=2 Î™®Îç∏ Ï±ÑÌÉù Í∂åÏû• (ÏÑ±Îä• Ïú†ÏßÄ/Ìñ•ÏÉÅ + Ïª§Î≤ÑÎ¶¨ÏßÄ Ï¶ùÍ∞Ä)\")\n",
                "        else:\n",
                "            logger.info(\"   ‚ö†Ô∏è min=2 Î™®Îç∏ ÏÑ±Îä• ÌïòÎùΩ. Ïª§Î≤ÑÎ¶¨ÏßÄ Ïù¥ÎìùÍ≥º Trade-off Í≥†Î†§ ÌïÑÏöî\")\n",
                "            \n",
                "else:\n",
                "    logger.warning(\"‚ö†Ô∏è ÌèâÍ∞ÄÎ•º ÏàòÌñâÌï† Îç∞Ïù¥ÌÑ∞ÎÇò Î™®Îç∏Ïù¥ Î∂ÄÏ°±Ìï©ÎãàÎã§.\")"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "authorship_tag": "ABX9TyNH0kkpa7G0Av5btbhV+ojA",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "song",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
