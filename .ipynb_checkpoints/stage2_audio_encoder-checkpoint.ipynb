{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Stage 2: Audio Encoder Training & Embedding Extraction\n",
                "\n",
                "이 노트북은 **Stage 2 오디오 파이프라인**을 구현합니다.\n",
                "1. **소형 멜-CNN 오디오 인코더**를 학습 (Contrastive Learning)\n",
                "2. 학습된 인코더로 곡별 오디오 임베딩을 추출하여 `.npz`로 저장\n",
                "\n",
                "**주요 흐름:**\n",
                "- Item2Vec 모델과 Mel Spectrogram 파일의 교집합 곡 리스트 생성\n",
                "- 학습용 서브셋(최대 5만 곡) 샘플링\n",
                "- Contrastive Learning (InfoNCE Loss) 수행\n",
                "- 학습된 모델로 임베딩 추출"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Cell 1] 환경 설정 & 기본 상수 정의\n",
                "\n",
                "import os\n",
                "import sys\n",
                "import json\n",
                "import random\n",
                "import glob\n",
                "import logging\n",
                "import tarfile\n",
                "import shutil\n",
                "from typing import List, Dict, Tuple, Optional, Set\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.utils.data as data\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "# 로깅 설정\n",
                "logging.basicConfig(level=logging.INFO)\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "def set_seed(seed: int = 42):\n",
                "    \"\"\"재현성을 위한 난수 시드 고정\"\"\"\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.manual_seed_all(seed)\n",
                "\n",
                "# --- 상수 및 하이퍼파라미터 정의 ---\n",
                "\n",
                "# Colab 여부 확인\n",
                "IS_COLAB = 'google.colab' in sys.modules\n",
                "\n",
                "# 경로 설정\n",
                "if IS_COLAB:\n",
                "    # Colab 환경 경로\n",
                "    DRIVE_MOUNT_PATH = \"/content/drive\"\n",
                "    # 사용자가 말한 \"Cola Notebooks\\meon-dataset\"에 대응\n",
                "    DRIVE_TAR_DIR = \"/content/drive/MyDrive/Cola Notebooks/meon-dataset\" \n",
                "    LOCAL_MEL_DIR = \"/content/mel_data\"  # 압축 풀 로컬 경로\n",
                "    ITEM2VEC_MODEL_PATH = \"/content/drive/MyDrive/path/to/v2_item2vec.model\" # TODO: 실제 드라이브 경로로 수정 필요\n",
                "    MELON_TAR_MAP_PATH = \"/content/drive/MyDrive/path/to/melon_tar_map.json\" # TODO: 실제 드라이브 경로로 수정 필요\n",
                "    STAGE2_EMB_OUTPUT_PATH = \"/content/drive/MyDrive/output/audio_embeddings_stage2.npz\"\n",
                "else:\n",
                "    # 로컬(Windows) 환경 경로\n",
                "    ITEM2VEC_MODEL_PATH = r\"C:\\Users\\ASUS\\music_recommend\\work\\models\\v2_item2vec.model\"\n",
                "    MELON_TAR_MAP_PATH = r\"C:\\Users\\ASUS\\music_recommend\\work\\melon_tar_map.json\"\n",
                "    LOCAL_MEL_DIR = r\"C:\\Users\\ASUS\\data\\arena_mel\" # 이미 압축 풀려있는 곳 가정\n",
                "    STAGE2_EMB_OUTPUT_PATH = r\"C:\\Users\\ASUS\\music_recommend\\work\\models\\audio_embeddings_stage2.npz\"\n",
                "\n",
                "# 오디오 처리 관련\n",
                "FIXED_T = 256  # 멜 스펙트로그램 시간축 고정 길이\n",
                "\n",
                "# 학습 하이퍼파라미터\n",
                "BATCH_SIZE = 64\n",
                "NUM_EPOCHS = 10\n",
                "LEARNING_RATE = 1e-3\n",
                "EMBED_DIM = 128\n",
                "TEMPERATURE = 0.1\n",
                "MAX_TRAIN_SONGS = 50000 \n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "logger.info(f\"Using device: {device}\")\n",
                "logger.info(f\"Running in Colab: {IS_COLAB}\")\n",
                "set_seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3879cb7a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Cell 2] 데이터 준비: Tar 매핑 로드 & 학습 데이터셋 준비 (Colab용 압축 해제)\n",
                "\n",
                "from gensim.models import Word2Vec\n",
                "\n",
                "def prepare_data_and_get_ids(item2vec_path: str, tar_map_path: str, max_songs: int) -> Tuple[List[str], Dict]:\n",
                "    # 1. Item2Vec 모델 로드\n",
                "    logger.info(f\"Loading Item2Vec model from {item2vec_path}...\")\n",
                "    if not os.path.exists(item2vec_path):\n",
                "        logger.error(f\"Item2Vec model not found at {item2vec_path}\")\n",
                "        return [], {}\n",
                "        \n",
                "    try:\n",
                "        model = Word2Vec.load(item2vec_path)\n",
                "        cf_song_ids = set(model.wv.key_to_index.keys())\n",
                "        logger.info(f\"Item2Vec vocab size: {len(cf_song_ids)}\")\n",
                "    except Exception as e:\n",
                "        logger.error(f\"Failed to load Item2Vec model: {e}\")\n",
                "        return [], {}\n",
                "\n",
                "    # 2. Tar Map 로드\n",
                "    logger.info(f\"Loading Tar Map from {tar_map_path}...\")\n",
                "    if not os.path.exists(tar_map_path):\n",
                "        logger.error(f\"Tar map not found at {tar_map_path}\")\n",
                "        return [], {}\n",
                "        \n",
                "    with open(tar_map_path, 'r') as f:\n",
                "        tar_map = json.load(f)\n",
                "    \n",
                "    # 3. 학습용 곡 샘플링\n",
                "    # CF 모델에 있는 곡들 중 실제로 멜론 데이터셋 범위(0~707988)에 들어가는지 확인\n",
                "    valid_song_ids = []\n",
                "    for sid in cf_song_ids:\n",
                "        try:\n",
                "            folder_id = str(int(sid) // 1000)\n",
                "            if folder_id in tar_map:\n",
                "                valid_song_ids.append(sid)\n",
                "        except:\n",
                "            continue\n",
                "            \n",
                "    logger.info(f\"Valid intersection songs: {len(valid_song_ids)}\")\n",
                "    \n",
                "    valid_song_ids.sort()\n",
                "    if len(valid_song_ids) > max_songs:\n",
                "        random.seed(42)\n",
                "        train_song_ids = random.sample(valid_song_ids, max_songs)\n",
                "        logger.info(f\"Sampled {max_songs} songs for training.\")\n",
                "    else:\n",
                "        train_song_ids = valid_song_ids\n",
                "        logger.info(f\"Using all {len(train_song_ids)} songs.\")\n",
                "\n",
                "    # 4. (Colab 전용) 필요한 Tar 파일만 복사 및 압축 해제\n",
                "    if IS_COLAB:\n",
                "        # 필요한 Tar 파일 식별\n",
                "        required_tars = set()\n",
                "        for sid in train_song_ids:\n",
                "            folder_id = str(int(sid) // 1000)\n",
                "            if folder_id in tar_map:\n",
                "                required_tars.add(tar_map[folder_id])\n",
                "        \n",
                "        logger.info(f\"Required Tar files ({len(required_tars)}): {list(required_tars)[:5]} ...\")\n",
                "        \n",
                "        # 드라이브 마운트\n",
                "        if not os.path.exists(DRIVE_MOUNT_PATH):\n",
                "            from google.colab import drive\n",
                "            drive.mount(DRIVE_MOUNT_PATH)\n",
                "            \n",
                "        os.makedirs(LOCAL_MEL_DIR, exist_ok=True)\n",
                "        \n",
                "        for tar_name in tqdm(required_tars, desc=\"Extracting Tars\"):\n",
                "            # 이미 압축 풀려있는지 체크 (폴더 존재 여부로 간단 확인)\n",
                "            folder_name = tar_name.replace('.tar', '')\n",
                "            expected_path = os.path.join(LOCAL_MEL_DIR, folder_name)\n",
                "            \n",
                "            if os.path.exists(expected_path):\n",
                "                continue\n",
                "                \n",
                "            tar_path = os.path.join(DRIVE_TAR_DIR, tar_name)\n",
                "            if os.path.exists(tar_path):\n",
                "                try:\n",
                "                    with tarfile.open(tar_path, 'r') as tar:\n",
                "                        # Tar 파일명으로 폴더를 만들어 그 안에 압축 해제 (구조 유지를 위해)\n",
                "                        extract_path = os.path.join(LOCAL_MEL_DIR, folder_name)\n",
                "                        os.makedirs(extract_path, exist_ok=True)\n",
                "                        tar.extractall(path=extract_path)\n",
                "                except Exception as e:\n",
                "                    logger.error(f\"Failed to extract {tar_name}: {e}\")\n",
                "            else:\n",
                "                logger.warning(f\"Tar file not found: {tar_path}\")\n",
                "\n",
                "    return train_song_ids, tar_map\n",
                "\n",
                "# 실행\n",
                "train_song_ids, tar_map = prepare_data_and_get_ids(ITEM2VEC_MODEL_PATH, MELON_TAR_MAP_PATH, MAX_TRAIN_SONGS)\n",
                "logger.info(f\"Final training song count: {len(train_song_ids)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Cell 3] 멜 스펙 로더 (디렉토리 구조 반영)\n",
                "\n",
                "def load_mel_spectrogram(song_id: str, base_dir: str = LOCAL_MEL_DIR, tar_map: Dict = tar_map) -> Optional[np.ndarray]:\n",
                "    \"\"\"\n",
                "    song_id에 해당하는 mel npy 파일을 로드합니다.\n",
                "    구조: {base_dir}/{tar_folder_name}/arena_mel/{folder_id}/{song_id}.npy\n",
                "    예: base_dir/arena_mel_0/arena_mel/0/0.npy\n",
                "    \"\"\"\n",
                "    try:\n",
                "        folder_id = str(int(song_id) // 1000)\n",
                "        if folder_id not in tar_map:\n",
                "            return None\n",
                "            \n",
                "        tar_name = tar_map[folder_id]\n",
                "        tar_folder_name = tar_name.replace('.tar', '') # arena_mel_0\n",
                "        \n",
                "        # 경로 조립\n",
                "        path = os.path.join(base_dir, tar_folder_name, \"arena_mel\", folder_id, f\"{song_id}.npy\")\n",
                "        \n",
                "        if not os.path.exists(path):\n",
                "            return None\n",
                "            \n",
                "        mel = np.load(path)\n",
                "        \n",
                "        # (48, T) 확인 및 Transpose\n",
                "        if mel.shape[0] != 48 and mel.shape[1] == 48:\n",
                "            mel = mel.T\n",
                "        return mel\n",
                "        \n",
                "    except Exception as e:\n",
                "        return None\n",
                "\n",
                "def random_crop(mel: np.ndarray, fixed_t: int = FIXED_T) -> np.ndarray:\n",
                "    \"\"\"멜 스펙트로그램을 fixed_t 길이로 랜덤 크롭하거나 패딩합니다.\"\"\"\n",
                "    n_freq, n_time = mel.shape\n",
                "    \n",
                "    if n_time >= fixed_t:\n",
                "        start = random.randint(0, n_time - fixed_t)\n",
                "        return mel[:, start:start+fixed_t]\n",
                "    else:\n",
                "        # 패딩 (중앙 정렬)\n",
                "        pad_total = fixed_t - n_time\n",
                "        pad_left = pad_total // 2\n",
                "        pad_right = pad_total - pad_left\n",
                "        return np.pad(mel, ((0, 0), (pad_left, pad_right)), mode='constant', constant_values=0)\n",
                "\n",
                "def augment_mel(mel: np.ndarray) -> np.ndarray:\n",
                "    \"\"\"간단한 데이터 증강\"\"\"\n",
                "    aug_mel = mel.copy()\n",
                "    # Noise\n",
                "    if random.random() < 0.5:\n",
                "        noise = np.random.normal(0, 0.005, aug_mel.shape)\n",
                "        aug_mel += noise\n",
                "    # Time Shift\n",
                "    if random.random() < 0.5:\n",
                "        shift = random.randint(-5, 5)\n",
                "        if shift != 0:\n",
                "            aug_mel = np.roll(aug_mel, shift, axis=1)\n",
                "    return aug_mel\n",
                "\n",
                "def mel_to_tensor(mel: np.ndarray) -> torch.Tensor:\n",
                "    return torch.from_numpy(mel).unsqueeze(0).float()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Cell 4] Contrastive Dataset & DataLoader 정의\n",
                "\n",
                "class ContrastiveMelDataset(data.Dataset):\n",
                "    def __init__(self, song_ids: List[str], mel_dir: str = LOCAL_MEL_DIR, tar_map: Dict = None):\n",
                "        self.song_ids = song_ids\n",
                "        self.mel_dir = mel_dir\n",
                "        self.tar_map = tar_map if tar_map is not None else {}\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.song_ids)\n",
                "    \n",
                "    def __getitem__(self, index):\n",
                "        song_id = self.song_ids[index]\n",
                "        \n",
                "        mel = load_mel_spectrogram(song_id, self.mel_dir, self.tar_map)\n",
                "        \n",
                "        if mel is None:\n",
                "            mel = np.zeros((48, FIXED_T))\n",
                "            \n",
                "        mel1 = random_crop(mel, FIXED_T)\n",
                "        mel2 = random_crop(mel, FIXED_T)\n",
                "        \n",
                "        mel1 = augment_mel(mel1)\n",
                "        mel2 = augment_mel(mel2)\n",
                "        \n",
                "        return {\n",
                "            \"song_id\": song_id,\n",
                "            \"anchor\": mel_to_tensor(mel1),\n",
                "            \"positive\": mel_to_tensor(mel2)\n",
                "        }\n",
                "\n",
                "def create_dataloader(song_ids: List[str], tar_map: Dict, batch_size: int = BATCH_SIZE):\n",
                "    dataset = ContrastiveMelDataset(song_ids, tar_map=tar_map)\n",
                "    return data.DataLoader(\n",
                "        dataset, \n",
                "        batch_size=batch_size, \n",
                "        shuffle=True, \n",
                "        num_workers=0, \n",
                "        drop_last=True\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Cell 5] 소형 멜-CNN 인코더 모델 정의\n",
                "\n",
                "class MelCNNEncoder(nn.Module):\n",
                "    def __init__(self, embed_dim: int = EMBED_DIM):\n",
                "        super().__init__()\n",
                "        \n",
                "        # Input: (batch, 1, 48, T)\n",
                "        self.features = nn.Sequential(\n",
                "            # Block 1\n",
                "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
                "            nn.BatchNorm2d(32),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2), # (32, 24, T/2)\n",
                "            \n",
                "            # Block 2\n",
                "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
                "            nn.BatchNorm2d(64),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2), # (64, 12, T/4)\n",
                "            \n",
                "            # Block 3\n",
                "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
                "            nn.BatchNorm2d(128),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2)  # (128, 6, T/8)\n",
                "        )\n",
                "        \n",
                "        # Global Average Pooling -> (batch, 128, 1, 1)\n",
                "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
                "        \n",
                "        # Projection Head\n",
                "        self.fc = nn.Sequential(\n",
                "            nn.Flatten(),\n",
                "            nn.Linear(128, embed_dim),\n",
                "            nn.LayerNorm(embed_dim)\n",
                "        )\n",
                "        \n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        x = self.features(x)\n",
                "        x = self.gap(x)\n",
                "        x = self.fc(x)\n",
                "        # L2 Normalize (Contrastive Learning에 필수)\n",
                "        x = F.normalize(x, p=2, dim=-1)\n",
                "        return x\n",
                "\n",
                "model = MelCNNEncoder(EMBED_DIM).to(device)\n",
                "logger.info(model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Cell 6] InfoNCE / SimCLR 스타일 Contrastive Loss 구현\n",
                "\n",
                "def info_nce_loss(z_i: torch.Tensor, z_j: torch.Tensor, temperature: float = TEMPERATURE) -> torch.Tensor:\n",
                "    \"\"\"\n",
                "    z_i, z_j: (batch_size, embed_dim) 형태의 L2 normalized 임베딩.\n",
                "    같은 인덱스끼리 positive 쌍, 나머지는 negative로 보는 InfoNCE loss.\n",
                "    \"\"\"\n",
                "    batch_size = z_i.shape[0]\n",
                "    \n",
                "    # (2N, D) 형태로 결합\n",
                "    z = torch.cat([z_i, z_j], dim=0)\n",
                "    \n",
                "    # 유사도 행렬 (2N, 2N)\n",
                "    sim = torch.matmul(z, z.T) / temperature\n",
                "    \n",
                "    # 자기 자신과의 유사도(diagonal)는 마스킹 (매우 작은 값으로)\n",
                "    sim_i_j = torch.diag(sim, batch_size)\n",
                "    sim_j_i = torch.diag(sim, -batch_size)\n",
                "    \n",
                "    # Positive 쌍: (i, i+batch_size) 및 (i+batch_size, i)\n",
                "    # 이를 위해 라벨을 생성\n",
                "    # 기준: 각 행(anchor)에 대해 정답 열(positive)의 인덱스\n",
                "    # 0~N-1 행의 정답은 N~2N-1\n",
                "    # N~2N-1 행의 정답은 0~N-1\n",
                "    \n",
                "    labels = torch.cat([\n",
                "        torch.arange(batch_size, 2 * batch_size, device=z.device),\n",
                "        torch.arange(0, batch_size, device=z.device)\n",
                "    ], dim=0)\n",
                "    \n",
                "    # 자기 자신 마스킹 (diagonal에 -inf)\n",
                "    mask = torch.eye(2 * batch_size, device=z.device).bool()\n",
                "    sim.masked_fill_(mask, -9e15)\n",
                "    \n",
                "    # Cross Entropy Loss\n",
                "    loss = F.cross_entropy(sim, labels)\n",
                "    return loss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Cell 7] 학습 루프 (Training Loop)\n",
                "\n",
                "def train_model():\n",
                "    if not train_song_ids:\n",
                "        logger.warning(\"No training songs found. Skipping training.\")\n",
                "        return\n",
                "\n",
                "    set_seed(42)\n",
                "    \n",
                "    # DataLoader 생성 (tar_map 전달)\n",
                "    train_loader = create_dataloader(train_song_ids, tar_map, BATCH_SIZE)\n",
                "    logger.info(f\"Starting training for {NUM_EPOCHS} epochs...\")\n",
                "    \n",
                "    # Optimizer\n",
                "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
                "    \n",
                "    for epoch in range(NUM_EPOCHS):\n",
                "        model.train()\n",
                "        total_loss = 0.0\n",
                "        \n",
                "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
                "        for batch in pbar:\n",
                "            anchor = batch['anchor'].to(device)\n",
                "            positive = batch['positive'].to(device)\n",
                "            \n",
                "            # Forward\n",
                "            z_i = model(anchor)\n",
                "            z_j = model(positive)\n",
                "            \n",
                "            # Loss\n",
                "            loss = info_nce_loss(z_i, z_j, TEMPERATURE)\n",
                "            \n",
                "            # Backward\n",
                "            optimizer.zero_grad()\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            \n",
                "            total_loss += loss.item()\n",
                "            pbar.set_postfix(loss=loss.item())\n",
                "            \n",
                "        avg_loss = total_loss / len(train_loader)\n",
                "        logger.info(f\"Epoch {epoch+1} done. Avg Loss: {avg_loss:.4f}\")\n",
                "        \n",
                "        # (선택) 체크포인트 저장\n",
                "        # torch.save(model.state_dict(), f\"mel_cnn_encoder_epoch{epoch+1}.pt\")\n",
                "\n",
                "# 학습 실행\n",
                "train_model()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Cell 8] 곡 임베딩 추출 함수 정의 (chunk 단위 처리 가능하게)\n",
                "\n",
                "def extract_embeddings_for_song_ids(\n",
                "    model: MelCNNEncoder,\n",
                "    song_ids: List[str],\n",
                "    output_path: str,\n",
                "    tar_map: Dict,\n",
                "    mel_dir: str = LOCAL_MEL_DIR\n",
                ") -> None:\n",
                "    \"\"\"\n",
                "    주어진 song_id 리스트에 대해 멜 스펙을 로드하고,\n",
                "    학습된 인코더로 임베딩을 추출해 .npz로 저장합니다.\n",
                "    \"\"\"\n",
                "    model.eval()\n",
                "    emb_dict: Dict[str, np.ndarray] = {}\n",
                "    \n",
                "    logger.info(f\"Extracting embeddings for {len(song_ids)} songs...\")\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for song_id in tqdm(song_ids):\n",
                "            mel = load_mel_spectrogram(song_id, mel_dir, tar_map)\n",
                "            if mel is None:\n",
                "                continue\n",
                "            \n",
                "            mel_crop = random_crop(mel, FIXED_T)\n",
                "            \n",
                "            tensor = mel_to_tensor(mel_crop).to(device)\n",
                "            \n",
                "            # (1, 1, 48, T) -> (1, D)\n",
                "            z = model(tensor.unsqueeze(0))\n",
                "            \n",
                "            # CPU numpy로 변환\n",
                "            emb_dict[song_id] = z.squeeze(0).cpu().numpy()\n",
                "            \n",
                "    # 저장\n",
                "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
                "    np.savez_compressed(output_path, **emb_dict)\n",
                "    logger.info(f\"Saved embeddings to {output_path} (Count: {len(emb_dict)})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Cell 9] 임베딩 추출 함수 예시 호출 (train_song_ids 대상으로)\n",
                "\n",
                "if train_song_ids:\n",
                "    extract_embeddings_for_song_ids(\n",
                "        model=model,\n",
                "        song_ids=train_song_ids,\n",
                "        output_path=STAGE2_EMB_OUTPUT_PATH,\n",
                "        tar_map=tar_map\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Cell 10] 간단 Sanity Check (이웃 곡 확인)\n",
                "\n",
                "def sanity_check_neighbors(emb_path: str, meta_path: str = r\"C:\\Users\\ASUS\\music_recommend\\work\\song_meta.json\"):\n",
                "    if not os.path.exists(emb_path):\n",
                "        logger.warning(\"Embedding file not found. Skipping sanity check.\")\n",
                "        return\n",
                "        \n",
                "    # 1. 임베딩 로드\n",
                "    data = np.load(emb_path)\n",
                "    keys = list(data.keys())\n",
                "    vectors = np.array([data[k] for k in keys]) # (N, D)\n",
                "    \n",
                "    logger.info(f\"Loaded {len(keys)} embeddings for sanity check.\")\n",
                "    \n",
                "    # 2. 메타데이터 로드 (Colab 환경 고려)\n",
                "    if IS_COLAB:\n",
                "        meta_path = \"/content/drive/MyDrive/path/to/song_meta.json\" # TODO: 수정 필요\n",
                "        \n",
                "    if not os.path.exists(meta_path):\n",
                "        logger.warning(f\"Meta file not found at {meta_path}\")\n",
                "        return\n",
                "\n",
                "    try:\n",
                "        with open(meta_path, 'r', encoding='utf-8') as f:\n",
                "            song_meta = json.load(f)\n",
                "        # id -> meta dict\n",
                "        meta_dict = {str(s['id']): s for s in song_meta}\n",
                "    except Exception as e:\n",
                "        logger.warning(f\"Failed to load song_meta: {e}\")\n",
                "        meta_dict = {}\n",
                "\n",
                "    # 3. 랜덤 시드 곡 몇 개 선정\n",
                "    n_seeds = 3\n",
                "    seeds = random.sample(keys, min(len(keys), n_seeds))\n",
                "    \n",
                "    for seed_id in seeds:\n",
                "        seed_vec = data[seed_id] # (D,)\n",
                "        \n",
                "        # 코사인 유사도 (이미 L2 정규화 되어있으므로 dot product)\n",
                "        sims = np.dot(vectors, seed_vec)\n",
                "        top_k_idx = np.argsort(sims)[::-1][:6] # 자기자신 포함 상위 6개\n",
                "        \n",
                "        print(f\"\\n[Seed Song] {meta_dict.get(seed_id, {}).get('song_name', seed_id)} / {meta_dict.get(seed_id, {}).get('artist_name_basket', [])}\")\n",
                "        print(\"-\" * 40)\n",
                "        \n",
                "        for idx in top_k_idx:\n",
                "            t_id = keys[idx]\n",
                "            t_score = sims[idx]\n",
                "            t_meta = meta_dict.get(t_id, {})\n",
                "            print(f\"{t_score:.4f} | {t_meta.get('song_name', t_id)} | {t_meta.get('artist_name_basket', [])} | {t_meta.get('gnr_basket', [])}\")\n",
                "\n",
                "# 실행\n",
                "sanity_check_neighbors(STAGE2_EMB_OUTPUT_PATH)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
